# Crackerjack Configuration Example
#
# This is an example configuration file for crackerjack.
# Copy this file to `.crackerjack.yaml` in your project root and customize.

# =============================================================================
# Pool Scanning Configuration
# =============================================================================
# Enable Mahavishnu worker pool integration for accelerated quality scanning
pool_scanning:
  # Enable pool-based scanning (3-4x speedup for slow tools)
  enabled: false

  # Mahavishnu MCP server URL
  mcp_server_url: "http://localhost:8680"

  pool:
    # Pool name for identification
    name: "crackerjack-quality-scanners"

    # Pool type: mahavishnu (local), session-buddy (memory-augmented), kubernetes (distributed)
    pool_type: "mahavishnu"

    # Worker range
    min_workers: 2
    max_workers: 8

    # Worker type: terminal-qwen, terminal-claude, or container
    worker_type: "terminal-qwen"

    # Auto-scaling
    autoscaling:
      enabled: true
      # Spawn more workers when pending tasks > 10
      scale_up_threshold: 10
      # Scale down when idle for 5 minutes (300 seconds)
      scale_down_threshold: 300
      max_workers: 16

  # Tools to execute in pools (slow, CPU-intensive tools)
  pooled_tools:
    - refurb
    - complexipy
    - skylos
    - semgrep
    - gitleaks

  # Tools to run locally (fast tools that don't benefit from pools)
  local_tools:
    - ruff
    - vulture
    - codespell
    - check-jsonschema

  # Memory integration (smart caching via session-buddy)
  memory:
    enabled: true
    cache_duration: 86400  # 24 hours in seconds

# =============================================================================
# Additional Settings (Existing Configuration)
# =============================================================================
# For other settings, see crackerjack/config/settings.py for available options

# Cleaning settings
cleaning:
  clean: true
  strip_comments_only: false
  strip_docstrings_only: false
  update_docs: false

# Hook settings
hooks:
  skip_hooks: false
  experimental_hooks: false

# Test settings
testing:
  test: false
  benchmark: false
  test_workers: 0
  test_timeout: 0
  incremental_tests: true
  auto_detect_workers: true
  max_workers: 8
  min_workers: 2
  memory_per_worker_gb: 2.0
  coverage: false

# Execution settings
execution:
  interactive: false
  verbose: false
  async_mode: false
  no_config_updates: false

# Progress settings
progress:
  enabled: false
  track_progress: true

# =============================================================================
# Notes
# =============================================================================
# 1. Pool scanning is EXPERIMENTAL and requires:
#    - Mahavishnu MCP server running on http://localhost:8680
#    - mcp-common >= 0.9.0 (with WebSocket support)
#    - Sufficient system resources for worker pools
#
# 2. Performance expectations (8 workers):
#    Small commits (5-10 files): 10-20s (30-60x faster)
#    Medium commits (10-50 files): 20-40s (15-30x faster)
#    Large commits (50+ files): 2-3 min (3-5x faster)
#    Full scan: 3-4 min (2.5-3x faster)
#
# 3. Memory integration reduces redundant scans by caching results for 24 hours
#
# 4. Auto-scaling adjusts workers based on load (2-16 workers range)
