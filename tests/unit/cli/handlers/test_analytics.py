"""Test analytics CLI handlers functionality."""

from __future__ import annotations

import json
from pathlib import Path
from unittest.mock import Mock, call, patch
from datetime import datetime

import pytest

# Module-level import pattern to avoid pytest conflicts
from crackerjack.cli.handlers import analytics


class TestHandleHeatmapGeneration:
    """Test handle_heatmap_generation function."""

    @patch("crackerjack.cli.handlers.analytics._generate_heatmap_by_type")
    @patch("crackerjack.cli.handlers.analytics._save_heatmap_output")
    @patch("crackerjack.services.heatmap_generator.HeatMapGenerator")
    @patch("crackerjack.cli.handlers.analytics.Path")
    def test_returns_true_when_heatmap_false(
        self, mock_path: Mock, mock_generator_class: Mock, mock_save: Mock, mock_generate: Mock
    ) -> None:
        """Test that function returns True when heatmap=False."""
        result = analytics.handle_heatmap_generation(
            heatmap=False, heatmap_type="error_frequency", heatmap_output=None
        )

        assert result is True
        mock_generator_class.assert_not_called()
        mock_generate.assert_not_called()
        mock_save.assert_not_called()

    @patch("crackerjack.cli.handlers.analytics._generate_heatmap_by_type")
    @patch("crackerjack.cli.handlers.analytics._save_heatmap_output")
    @patch("crackerjack.services.heatmap_generator.HeatMapGenerator")
    @patch("crackerjack.cli.handlers.analytics.Path")
    def test_generates_heatmap_by_correct_type(
        self, mock_path: Mock, mock_generator_class: Mock, mock_save: Mock, mock_generate: Mock
    ) -> None:
        """Test that heatmap is generated by correct type."""
        mock_generator = Mock()
        mock_generator_class.return_value = mock_generator
        mock_heatmap_data = {"files": [{"path": "test.py", "value": 5}]}
        mock_generate.return_value = mock_heatmap_data
        mock_path.cwd.return_value = Mock()

        result = analytics.handle_heatmap_generation(
            heatmap=True, heatmap_type="complexity", heatmap_output=None
        )

        mock_generate.assert_called_once()
        call_args = mock_generate.call_args
        assert call_args[0][1] == "complexity"

    @patch("crackerjack.cli.handlers.analytics._generate_heatmap_by_type")
    @patch("crackerjack.cli.handlers.analytics._save_heatmap_output")
    @patch("crackerjack.services.heatmap_generator.HeatMapGenerator")
    @patch("crackerjack.cli.handlers.analytics.Path")
    def test_saves_heatmap_output_successfully(
        self, mock_path: Mock, mock_generator_class: Mock, mock_save: Mock, mock_generate: Mock
    ) -> None:
        """Test that heatmap output is saved successfully."""
        mock_generator = Mock()
        mock_generator_class.return_value = mock_generator
        mock_heatmap_data = {"files": [{"path": "test.py", "value": 5}]}
        mock_generate.return_value = mock_heatmap_data
        mock_save.return_value = True
        mock_path.cwd.return_value = Mock()

        result = analytics.handle_heatmap_generation(
            heatmap=True, heatmap_type="error_frequency", heatmap_output="output.html"
        )

        mock_save.assert_called_once()
        call_args = mock_save.call_args
        assert call_args[0][1] == mock_heatmap_data

    @patch("crackerjack.cli.handlers.analytics._generate_heatmap_by_type")
    @patch("crackerjack.cli.handlers.analytics._save_heatmap_output")
    @patch("crackerjack.services.heatmap_generator.HeatMapGenerator")
    @patch("crackerjack.cli.handlers.analytics.Path")
    def test_returns_false_when_heatmap_generated_successfully(
        self, mock_path: Mock, mock_generator_class: Mock, mock_save: Mock, mock_generate: Mock
    ) -> None:
        """Test that function returns False when heatmap generated successfully."""
        mock_generator = Mock()
        mock_generator_class.return_value = mock_generator
        mock_heatmap_data = {"files": [{"path": "test.py", "value": 5}]}
        mock_generate.return_value = mock_heatmap_data
        mock_save.return_value = True
        mock_path.cwd.return_value = Mock()

        result = analytics.handle_heatmap_generation(
            heatmap=True, heatmap_type="quality_metrics", heatmap_output=None
        )

        assert result is False


class TestGenerateHeatmapByType:
    """Test _generate_heatmap_by_type function."""

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_calls_generate_error_frequency_heatmap_for_error_frequency(
        self, mock_console: Mock
    ) -> None:
        """Test that generate_error_frequency_heatmap is called for error_frequency type."""
        mock_generator = Mock()
        mock_heatmap_data = {"files": [{"path": "test.py"}]}
        mock_generator.generate_error_frequency_heatmap.return_value = mock_heatmap_data

        result = analytics._generate_heatmap_by_type(
            mock_generator, "error_frequency", Path("/test"), mock_console
        )

        assert result == mock_heatmap_data
        mock_generator.generate_error_frequency_heatmap.assert_called_once()

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_calls_generate_code_complexity_heatmap_for_complexity(
        self, mock_console: Mock
    ) -> None:
        """Test that generate_code_complexity_heatmap is called for complexity type."""
        mock_generator = Mock()
        mock_heatmap_data = {"files": [{"path": "test.py"}]}
        mock_generator.generate_code_complexity_heatmap.return_value = mock_heatmap_data

        result = analytics._generate_heatmap_by_type(
            mock_generator, "complexity", Path("/test"), mock_console
        )

        assert result == mock_heatmap_data
        mock_generator.generate_code_complexity_heatmap.assert_called_once()

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_calls_generate_quality_metrics_heatmap_for_quality_metrics(
        self, mock_console: Mock
    ) -> None:
        """Test that generate_quality_metrics_heatmap is called for quality_metrics type."""
        mock_generator = Mock()
        mock_heatmap_data = {"files": [{"path": "test.py"}]}
        mock_generator.generate_quality_metrics_heatmap.return_value = mock_heatmap_data

        result = analytics._generate_heatmap_by_type(
            mock_generator, "quality_metrics", Path("/test"), mock_console
        )

        assert result == mock_heatmap_data
        mock_generator.generate_quality_metrics_heatmap.assert_called_once()

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_calls_generate_test_failure_heatmap_for_test_failures(
        self, mock_console: Mock
    ) -> None:
        """Test that generate_test_failure_heatmap is called for test_failures type."""
        mock_generator = Mock()
        mock_heatmap_data = {"files": [{"path": "test.py"}]}
        mock_generator.generate_test_failure_heatmap.return_value = mock_heatmap_data

        result = analytics._generate_heatmap_by_type(
            mock_generator, "test_failures", Path("/test"), mock_console
        )

        assert result == mock_heatmap_data
        mock_generator.generate_test_failure_heatmap.assert_called_once()

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_returns_none_for_unknown_heatmap_type(
        self, mock_console: Mock
    ) -> None:
        """Test that None is returned for unknown heatmap type."""
        mock_generator = Mock()

        result = analytics._generate_heatmap_by_type(
            mock_generator, "unknown_type", Path("/test"), mock_console
        )

        assert result is None

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_prints_error_message_for_unknown_type(
        self, mock_console: Mock
    ) -> None:
        """Test that error message is printed for unknown type."""
        mock_generator = Mock()

        analytics._generate_heatmap_by_type(
            mock_generator, "unknown_type", Path("/test"), mock_console
        )

        mock_console.print.assert_called()
        call_args = mock_console.print.call_args
        assert "Unknown heat map type" in str(call_args)


class TestSaveHeatmapOutput:
    """Test _save_heatmap_output function."""

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_saves_html_output_when_html_suffix(
        self, mock_console: Mock, mock_path: Mock
    ) -> None:
        """Test that HTML visualization is saved when .html suffix."""
        mock_generator = Mock()
        mock_html_content = "<html>heatmap</html>"
        mock_generator.generate_html_visualization.return_value = mock_html_content
        mock_heatmap_data = {"files": [{"path": "test.py"}]}
        mock_file = Mock()
        mock_file.suffix = ".html"
        mock_path.return_value = mock_file

        result = analytics._save_heatmap_output(
            mock_generator, mock_heatmap_data, "output.html", "error_frequency", mock_console
        )

        assert result is True
        mock_generator.generate_html_visualization.assert_called_once_with(mock_heatmap_data)
        mock_file.write_text.assert_called_once_with(mock_html_content, encoding="utf-8")

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_saves_json_output_when_json_suffix(
        self, mock_console: Mock, mock_path: Mock
    ) -> None:
        """Test that JSON data is exported when .json suffix."""
        mock_generator = Mock()
        mock_heatmap_data = {"files": [{"path": "test.py"}]}
        mock_file = Mock()
        mock_file.suffix = ".json"
        mock_path.return_value = mock_file

        result = analytics._save_heatmap_output(
            mock_generator, mock_heatmap_data, "output.json", "complexity", mock_console
        )

        assert result is True
        mock_generator.export_heatmap_data.assert_called_once_with(
            mock_heatmap_data, mock_file, "json"
        )

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_saves_csv_output_when_csv_suffix(
        self, mock_console: Mock, mock_path: Mock
    ) -> None:
        """Test that CSV data is exported when .csv suffix."""
        mock_generator = Mock()
        mock_heatmap_data = {"files": [{"path": "test.py"}]}
        mock_file = Mock()
        mock_file.suffix = ".csv"
        mock_path.return_value = mock_file

        result = analytics._save_heatmap_output(
            mock_generator, mock_heatmap_data, "output.csv", "quality_metrics", mock_console
        )

        assert result is True
        mock_generator.export_heatmap_data.assert_called_once_with(
            mock_heatmap_data, mock_file, "csv"
        )

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_returns_false_for_unsupported_format(
        self, mock_console: Mock
    ) -> None:
        """Test that False is returned for unsupported format."""
        mock_generator = Mock()
        mock_heatmap_data = {"files": [{"path": "test.py"}]}

        result = analytics._save_heatmap_output(
            mock_generator, mock_heatmap_data, "output.txt", "test_failures", mock_console
        )

        assert result is False

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_saves_to_default_filename_when_no_output_path(
        self, mock_console: Mock, mock_path: Mock
    ) -> None:
        """Test that default filename is used when no output path provided."""
        mock_generator = Mock()
        mock_heatmap_data = {"files": [{"path": "test.py"}]}
        mock_html_content = "<html>heatmap</html>"
        mock_generator.generate_html_visualization.return_value = mock_html_content
        mock_file = Mock()
        mock_file.suffix = ".html"
        mock_path.return_value = mock_file

        result = analytics._save_heatmap_output(
            mock_generator, mock_heatmap_data, None, "error_frequency", mock_console
        )

        assert result is True
        mock_path.assert_called()
        # Check that Path was called with default filename
        call_args = [str(call[0][0]) for call in mock_path.call_args_list]
        assert "heatmap_error_frequency.html" in call_args

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_writes_file_with_correct_content(
        self, mock_console: Mock, mock_path: Mock
    ) -> None:
        """Test that file is written with correct content."""
        mock_generator = Mock()
        mock_heatmap_data = {"files": [{"path": "test.py"}]}
        mock_html_content = "<html>heatmap</html>"
        mock_generator.generate_html_visualization.return_value = mock_html_content
        mock_file = Mock()
        mock_file.suffix = ".html"
        mock_path.return_value = mock_file

        analytics._save_heatmap_output(
            mock_generator, mock_heatmap_data, "output.html", "error_frequency", mock_console
        )

        mock_file.write_text.assert_called_once_with(mock_html_content, encoding="utf-8")


class TestGenerateAnomalySampleData:
    """Test generate_anomaly_sample_data function."""

    def test_generates_50_data_points(self) -> None:
        """Test that 50 data points are generated."""
        mock_detector = Mock()

        analytics.generate_anomaly_sample_data(mock_detector)

        assert mock_detector.add_metric.call_count == 250  # 50 points * 5 metrics

    def test_covers_5_metric_types(self) -> None:
        """Test that 5 metric types are covered."""
        mock_detector = Mock()

        analytics.generate_anomaly_sample_data(mock_detector)

        # Check that all 5 metric types were used
        metric_types = {call[0][0] for call in mock_detector.add_metric.call_args_list}
        expected_types = {"test_pass_rate", "coverage_percentage", "complexity_score",
                         "execution_time", "error_count"}
        assert metric_types == expected_types

    def test_adds_metrics_to_detector(self) -> None:
        """Test that metrics are added to detector."""
        mock_detector = Mock()

        analytics.generate_anomaly_sample_data(mock_detector)

        assert mock_detector.add_metric.called


class TestGetSampleMetricValue:
    """Test get_sample_metric_value function."""

    def test_has_10_percent_anomaly_rate(self) -> None:
        """Test that there's 10% chance of anomaly."""
        # Test value is in expected range (either anomaly 0.3-0.7 or normal 0.85-0.98)
        result = analytics.get_sample_metric_value("test_pass_rate")

        # Should be in either anomaly range or normal range for test_pass_rate
        assert (0.3 <= result <= 0.7) or (0.85 <= result <= 0.98)

    def test_test_pass_rate_ranges(self) -> None:
        """Test test_pass_rate value ranges."""
        # Test that values are in expected ranges
        results = [analytics.get_sample_metric_value("test_pass_rate") for _ in range(20)]
        # All results should be in valid range
        assert all(0.3 <= r <= 0.98 for r in results)

    def test_coverage_percentage_ranges(self) -> None:
        """Test coverage_percentage value ranges."""
        # Test that values are in expected ranges
        results = [analytics.get_sample_metric_value("coverage_percentage") for _ in range(20)]
        # All results should be in valid range
        assert all(40 <= r <= 95 for r in results)

    def test_complexity_score_ranges(self) -> None:
        """Test complexity_score value ranges."""
        # Test that values are in expected ranges
        results = [analytics.get_sample_metric_value("complexity_score") for _ in range(20)]
        # All results should be in valid range
        assert all(8 <= r <= 35 for r in results)

    def test_execution_time_ranges(self) -> None:
        """Test execution_time value ranges."""
        # Test that values are in expected ranges
        results = [analytics.get_sample_metric_value("execution_time") for _ in range(20)]
        # All results should be in valid range
        assert all(30 <= r <= 600 for r in results)

    def test_error_count_ranges(self) -> None:
        """Test error_count value ranges."""
        # Test that values are in expected ranges
        results = [analytics.get_sample_metric_value("error_count") for _ in range(20)]
        # All results should be in valid range
        assert all(0 <= r <= 15 for r in results)


class TestDisplayAnomalyResults:
    """Test display_anomaly_results function."""

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_prints_baseline_and_anomaly_counts(self, mock_console: Mock) -> None:
        """Test that baseline and anomaly counts are printed."""
        mock_anomalies = []
        mock_baselines = {"metric1": {"mean": 10, "stddev": 2}}

        analytics.display_anomaly_results(mock_anomalies, mock_baselines)

        # Verify console.print was called
        assert mock_console.print.called

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_displays_top_5_anomalies(self, mock_console: Mock) -> None:
        """Test that top 5 anomalies are displayed."""
        # Create 7 mock anomalies with string severity values
        severity_levels = ["low", "medium", "high", "critical", "low", "medium", "high"]
        mock_anomalies = [Mock(severity=severity_levels[i]) for i in range(7)]
        mock_baselines = {"metric1": {"mean": 10, "stddev": 2}}

        analytics.display_anomaly_results(mock_anomalies, mock_baselines)

        # Should have called print multiple times
        assert mock_console.print.call_count > 1

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_color_codes_severity_levels(self, mock_console: Mock) -> None:
        """Test that severity levels are color-coded."""
        mock_anomaly = Mock()
        mock_anomaly.severity = "high"  # Changed from float to string
        mock_anomalies = [mock_anomaly]
        mock_baselines = {"metric1": {"mean": 10, "stddev": 2}}

        analytics.display_anomaly_results(mock_anomalies, mock_baselines)

        # Verify color coding was used
        assert mock_console.print.called

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_handles_empty_anomaly_list(self, mock_console: Mock) -> None:
        """Test that empty anomaly list is handled gracefully."""
        mock_anomalies = []
        mock_baselines = {}

        analytics.display_anomaly_results(mock_anomalies, mock_baselines)

        # Should still print summary
        assert mock_console.print.called


class TestSaveAnomalyReport:
    """Test save_anomaly_report function."""

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_creates_report_dict_with_correct_structure(
        self, mock_console: Mock, mock_path: Mock
    ) -> None:
        """Test that report dict has correct structure."""
        # Create proper Mock objects with all required attributes
        from datetime import datetime

        mock_anomaly = Mock()
        mock_anomaly.timestamp = datetime(2024, 1, 1, 0, 0, 0)
        mock_anomaly.metric_type = "metric1"
        mock_anomaly.value = 15.0
        mock_anomaly.expected_range = (8.0, 12.0)
        mock_anomaly.severity = "high"
        mock_anomaly.confidence = 0.95
        mock_anomaly.description = "Test anomaly"

        mock_anomalies = [mock_anomaly]
        mock_baselines = {"metric1": {"mean": 10, "stddev": 2}}
        mock_file = Mock()
        mock_path.return_value = mock_file

        analytics.save_anomaly_report(
            mock_anomalies, mock_baselines, 0.5, "report.json"
        )

        # Verify write_text was called
        assert mock_file.write_text.called

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_writes_json_to_file(self, mock_console: Mock, mock_path: Mock) -> None:
        """Test that JSON is written to file."""
        mock_anomalies = []
        mock_baselines = {}
        mock_file = Mock()
        mock_path.return_value = mock_file

        analytics.save_anomaly_report(
            mock_anomalies, mock_baselines, 0.5, "report.json"
        )

        assert mock_file.write_text.called
        # Verify it's valid JSON
        written_content = mock_file.write_text.call_args[0][0]
        json.loads(written_content)  # Should not raise

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_includes_timestamp_summary_anomalies_baselines(
        self, mock_console: Mock, mock_path: Mock
    ) -> None:
        """Test that report includes timestamp, summary, anomalies, baselines."""
        mock_anomalies = []
        mock_baselines = {}
        mock_file = Mock()
        mock_path.return_value = mock_file

        analytics.save_anomaly_report(
            mock_anomalies, mock_baselines, 0.5, "report.json"
        )

        written_content = mock_file.write_text.call_args[0][0]
        report = json.loads(written_content)

        assert "timestamp" in report
        assert "summary" in report
        assert "anomalies" in report
        assert "baselines" in report

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_prints_success_message(self, mock_console: Mock, mock_path: Mock) -> None:
        """Test that success message is printed."""
        mock_anomalies = []
        mock_baselines = {}
        mock_file = Mock()
        mock_path.return_value = mock_file

        analytics.save_anomaly_report(
            mock_anomalies, mock_baselines, 0.5, "report.json"
        )

        mock_console.print.assert_called()


class TestHandleAnomalyDetection:
    """Test handle_anomaly_detection function."""

    @patch("crackerjack.cli.handlers.analytics.display_anomaly_results")
    @patch("crackerjack.cli.handlers.analytics.save_anomaly_report")
    @patch("crackerjack.cli.handlers.analytics.generate_anomaly_sample_data")
    @patch("crackerjack.services.quality.anomaly_detector.AnomalyDetector")
    def test_returns_true_when_anomaly_detection_false(
        self, mock_detector_class: Mock, mock_generate: Mock,
        mock_save: Mock, mock_display: Mock
    ) -> None:
        """Test that function returns True when anomaly_detection=False."""
        result = analytics.handle_anomaly_detection(
            anomaly_detection=False, anomaly_sensitivity=0.5, anomaly_report=None
        )

        assert result is True
        mock_detector_class.assert_not_called()

    @patch("crackerjack.cli.handlers.analytics.display_anomaly_results")
    @patch("crackerjack.cli.handlers.analytics.save_anomaly_report")
    @patch("crackerjack.cli.handlers.analytics.generate_anomaly_sample_data")
    @patch("crackerjack.services.quality.anomaly_detector.AnomalyDetector")
    def test_creates_anomaly_detector_with_sensitivity(
        self, mock_detector_class: Mock, mock_generate: Mock,
        mock_save: Mock, mock_display: Mock
    ) -> None:
        """Test that AnomalyDetector is created with correct sensitivity."""
        mock_detector = Mock()
        mock_detector_class.return_value = mock_detector
        mock_detector.get_anomalies.return_value = []
        mock_detector.get_baseline_summary.return_value = {}

        analytics.handle_anomaly_detection(
            anomaly_detection=True, anomaly_sensitivity=0.7, anomaly_report=None
        )

        mock_detector_class.assert_called_once_with(sensitivity=0.7)

    @patch("crackerjack.cli.handlers.analytics.display_anomaly_results")
    @patch("crackerjack.cli.handlers.analytics.save_anomaly_report")
    @patch("crackerjack.cli.handlers.analytics.generate_anomaly_sample_data")
    @patch("crackerjack.services.quality.anomaly_detector.AnomalyDetector")
    def test_generates_sample_data(
        self, mock_detector_class: Mock, mock_generate: Mock,
        mock_save: Mock, mock_display: Mock
    ) -> None:
        """Test that sample data is generated."""
        mock_detector = Mock()
        mock_detector_class.return_value = mock_detector
        mock_detector.get_anomalies.return_value = []
        mock_detector.get_baseline_summary.return_value = {}

        analytics.handle_anomaly_detection(
            anomaly_detection=True, anomaly_sensitivity=0.5, anomaly_report=None
        )

        mock_generate.assert_called_once_with(mock_detector)

    @patch("crackerjack.cli.handlers.analytics.display_anomaly_results")
    @patch("crackerjack.cli.handlers.analytics.save_anomaly_report")
    @patch("crackerjack.cli.handlers.analytics.generate_anomaly_sample_data")
    @patch("crackerjack.services.quality.anomaly_detector.AnomalyDetector")
    def test_gets_anomalies_and_baselines(
        self, mock_detector_class: Mock, mock_generate: Mock,
        mock_save: Mock, mock_display: Mock
    ) -> None:
        """Test that anomalies and baselines are retrieved."""
        mock_detector = Mock()
        mock_detector_class.return_value = mock_detector
        mock_anomalies = []
        mock_baselines = {}
        mock_detector.get_anomalies.return_value = mock_anomalies
        mock_detector.get_baseline_summary.return_value = mock_baselines

        analytics.handle_anomaly_detection(
            anomaly_detection=True, anomaly_sensitivity=0.5, anomaly_report=None
        )

        mock_detector.get_anomalies.assert_called_once()
        mock_detector.get_baseline_summary.assert_called_once()

    @patch("crackerjack.cli.handlers.analytics.display_anomaly_results")
    @patch("crackerjack.cli.handlers.analytics.save_anomaly_report")
    @patch("crackerjack.cli.handlers.analytics.generate_anomaly_sample_data")
    @patch("crackerjack.services.quality.anomaly_detector.AnomalyDetector")
    def test_saves_report_when_path_provided(
        self, mock_detector_class: Mock, mock_generate: Mock,
        mock_save: Mock, mock_display: Mock
    ) -> None:
        """Test that report is saved when path is provided."""
        mock_detector = Mock()
        mock_detector_class.return_value = mock_detector
        mock_detector.get_anomalies.return_value = []
        mock_detector.get_baseline_summary.return_value = {}

        analytics.handle_anomaly_detection(
            anomaly_detection=True, anomaly_sensitivity=0.5, anomaly_report="report.json"
        )

        mock_save.assert_called_once()


class TestGeneratePredictiveSampleData:
    """Test generate_predictive_sample_data function."""

    def test_generates_48_data_points(self) -> None:
        """Test that 48 data points are generated."""
        mock_engine = Mock()

        result = analytics.generate_predictive_sample_data(mock_engine)

        assert mock_engine.add_metric.call_count == 240  # 48 points * 5 metrics

    def test_covers_5_metric_types(self) -> None:
        """Test that 5 metric types are covered."""
        mock_engine = Mock()

        result = analytics.generate_predictive_sample_data(mock_engine)

        # Check that all 5 metric types were used
        metric_types = {call[0][0] for call in mock_engine.add_metric.call_args_list}
        expected_types = {"test_pass_rate", "coverage_percentage", "complexity_score",
                         "execution_time", "memory_usage"}
        assert metric_types == expected_types

    def test_adds_metrics_to_engine(self) -> None:
        """Test that metrics are added to engine."""
        mock_engine = Mock()

        result = analytics.generate_predictive_sample_data(mock_engine)

        assert mock_engine.add_metric.called
        assert isinstance(result, list)


class TestGeneratePredictionsSummary:
    """Test generate_predictions_summary function."""

    def test_gets_trend_summary_from_engine(self) -> None:
        """Test that trend summary is retrieved from engine."""
        mock_engine = Mock()
        mock_trend_summary = {"metric1": {"trend": "increasing"}}
        mock_engine.get_trend_summary.return_value = mock_trend_summary
        mock_engine.predict_metric.return_value = []

        result = analytics.generate_predictions_summary(
            mock_engine, ["metric1"], 5
        )

        mock_engine.get_trend_summary.assert_called_once()

    def test_calls_predict_metric_for_each_type(self) -> None:
        """Test that predict_metric is called for each metric type."""
        mock_engine = Mock()
        mock_engine.get_trend_summary.return_value = {}
        mock_engine.predict_metric.return_value = []

        analytics.generate_predictions_summary(
            mock_engine, ["metric1", "metric2"], 5
        )

        assert mock_engine.predict_metric.call_count == 2

    def test_builds_predictions_dict_correctly(self) -> None:
        """Test that predictions dict is built correctly."""
        from datetime import datetime

        mock_engine = Mock()
        mock_engine.get_trend_summary.return_value = {
            "metric1": {"trend": "increasing", "strength": 0.8}
        }

        # Create proper mock prediction with all required attributes
        mock_prediction = Mock()
        mock_prediction.predicted_for = datetime(2025, 1, 1, 0, 0, 0)
        mock_prediction.predicted_value = 10.5
        mock_prediction.confidence_interval = (9.0, 12.0)
        mock_prediction.model_accuracy = 0.95

        mock_engine.predict_metric.return_value = [mock_prediction]

        result = analytics.generate_predictions_summary(
            mock_engine, ["metric1"], 5
        )

        assert "metric1" in result
        assert "trend" in result["metric1"]
        assert "predictions" in result["metric1"]

    def test_returns_summary_dict(self) -> None:
        """Test that summary dict is returned."""
        mock_engine = Mock()
        mock_engine.get_trend_summary.return_value = {}
        mock_engine.predict_metric.return_value = []

        result = analytics.generate_predictions_summary(
            mock_engine, ["metric1"], 5
        )

        assert isinstance(result, dict)


class TestDisplayTrendAnalysis:
    """Test display_trend_analysis function."""

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_prints_trend_analysis_header(self, mock_console: Mock) -> None:
        """Test that trend analysis header is printed."""
        mock_summary = {
            "metric1": {
                "trend": {"trend_direction": "increasing", "trend_strength": 0.8},
                "predictions": []
            }
        }

        analytics.display_trend_analysis(mock_summary)

        assert mock_console.print.called

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_displays_direction_with_color_coding(self, mock_console: Mock) -> None:
        """Test that direction is displayed with color coding."""
        mock_summary = {
            "metric1": {
                "trend": {"trend_direction": "increasing", "trend_strength": 0.8},
                "predictions": []
            }
        }

        analytics.display_trend_analysis(mock_summary)

        # Verify color coding was used
        assert mock_console.print.called

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_displays_next_prediction_with_confidence(self, mock_console: Mock) -> None:
        """Test that next prediction is displayed with confidence."""
        # Create prediction as dict with proper structure
        mock_prediction = {
            "predicted_for": "2025-01-01T00:00:00",
            "predicted_value": 10.5,
            "confidence_interval": [9.0, 12.0],
            "model_accuracy": 0.95,
        }
        mock_summary = {
            "metric1": {
                "trend": {"trend_direction": "increasing", "trend_strength": 0.8},
                "predictions": [mock_prediction]
            }
        }

        analytics.display_trend_analysis(mock_summary)

        assert mock_console.print.called

    @patch("crackerjack.cli.handlers.analytics.console")
    def test_handles_multiple_metric_types(self, mock_console: Mock) -> None:
        """Test that multiple metric types are handled."""
        mock_summary = {
            "metric1": {
                "trend": {"direction": "increasing", "strength": 0.8},
                "predictions": []
            },
            "metric2": {
                "trend": {"direction": "decreasing", "strength": 0.6},
                "predictions": []
            }
        }

        analytics.display_trend_analysis(mock_summary)

        # Should print for both metrics
        assert mock_console.print.call_count > 2


class TestSaveAnalyticsDashboard:
    """Test save_analytics_dashboard function."""

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_creates_dashboard_dict_with_correct_structure(
        self, mock_console: Mock, mock_path: Mock
    ) -> None:
        """Test that dashboard dict has correct structure."""
        mock_predictions_summary = {}
        mock_trend_summary = {}
        mock_metric_types = ["metric1"]
        mock_file = Mock()
        mock_path.return_value = mock_file

        analytics.save_analytics_dashboard(
            mock_predictions_summary, mock_trend_summary,
            mock_metric_types, 5, "dashboard.json"
        )

        assert mock_file.write_text.called

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_writes_json_to_file(self, mock_console: Mock, mock_path: Mock) -> None:
        """Test that JSON is written to file."""
        mock_predictions_summary = {}
        mock_trend_summary = {}
        mock_metric_types = []
        mock_file = Mock()
        mock_path.return_value = mock_file

        analytics.save_analytics_dashboard(
            mock_predictions_summary, mock_trend_summary,
            mock_metric_types, 5, "dashboard.json"
        )

        assert mock_file.write_text.called
        # Verify it's valid JSON
        written_content = mock_file.write_text.call_args[0][0]
        json.loads(written_content)  # Should not raise

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_includes_timestamp_summary_trends_predictions(
        self, mock_console: Mock, mock_path: Mock
    ) -> None:
        """Test that dashboard includes timestamp, summary, trends, predictions."""
        mock_predictions_summary = {"metric1": {"predictions": []}}
        mock_trend_summary = {}
        mock_metric_types = ["metric1"]
        mock_file = Mock()
        mock_path.return_value = mock_file

        analytics.save_analytics_dashboard(
            mock_predictions_summary, mock_trend_summary,
            mock_metric_types, 5, "dashboard.json"
        )

        written_content = mock_file.write_text.call_args[0][0]
        dashboard = json.loads(written_content)

        assert "timestamp" in dashboard
        assert "summary" in dashboard
        assert "trends" in dashboard
        assert "predictions" in dashboard

    @patch("crackerjack.cli.handlers.analytics.Path")
    @patch("crackerjack.cli.handlers.analytics.console")
    def test_prints_success_message(self, mock_console: Mock, mock_path: Mock) -> None:
        """Test that success message is printed."""
        mock_predictions_summary = {}
        mock_trend_summary = {}
        mock_metric_types = []
        mock_file = Mock()
        mock_path.return_value = mock_file

        analytics.save_analytics_dashboard(
            mock_predictions_summary, mock_trend_summary,
            mock_metric_types, 5, "dashboard.json"
        )

        mock_console.print.assert_called()


class TestHandlePredictiveAnalytics:
    """Test handle_predictive_analytics function."""

    @patch("crackerjack.cli.handlers.analytics.display_trend_analysis")
    @patch("crackerjack.cli.handlers.analytics.save_analytics_dashboard")
    @patch("crackerjack.cli.handlers.analytics.generate_predictions_summary")
    @patch("crackerjack.cli.handlers.analytics.generate_predictive_sample_data")
    @patch("crackerjack.services.ai.predictive_analytics.PredictiveAnalyticsEngine")
    def test_returns_true_when_predictive_analytics_false(
        self, mock_engine_class: Mock, mock_generate: Mock,
        mock_summary: Mock, mock_save: Mock, mock_display: Mock
    ) -> None:
        """Test that function returns True when predictive_analytics=False."""
        result = analytics.handle_predictive_analytics(
            predictive_analytics=False, prediction_periods=5, analytics_dashboard=None
        )

        assert result is True
        mock_engine_class.assert_not_called()

    @patch("crackerjack.cli.handlers.analytics.display_trend_analysis")
    @patch("crackerjack.cli.handlers.analytics.save_analytics_dashboard")
    @patch("crackerjack.cli.handlers.analytics.generate_predictions_summary")
    @patch("crackerjack.cli.handlers.analytics.generate_predictive_sample_data")
    @patch("crackerjack.services.ai.predictive_analytics.PredictiveAnalyticsEngine")
    def test_creates_predictive_analytics_engine(
        self, mock_engine_class: Mock, mock_generate: Mock,
        mock_summary: Mock, mock_save: Mock, mock_display: Mock
    ) -> None:
        """Test that PredictiveAnalyticsEngine is created."""
        mock_engine = Mock()
        mock_engine_class.return_value = mock_engine
        mock_engine.get_trend_summary.return_value = {}
        mock_generate.return_value = ["metric1"]
        mock_summary.return_value = {}

        analytics.handle_predictive_analytics(
            predictive_analytics=True, prediction_periods=5, analytics_dashboard=None
        )

        mock_engine_class.assert_called_once()

    @patch("crackerjack.cli.handlers.analytics.display_trend_analysis")
    @patch("crackerjack.cli.handlers.analytics.save_analytics_dashboard")
    @patch("crackerjack.cli.handlers.analytics.generate_predictions_summary")
    @patch("crackerjack.cli.handlers.analytics.generate_predictive_sample_data")
    @patch("crackerjack.services.ai.predictive_analytics.PredictiveAnalyticsEngine")
    def test_generates_sample_data(
        self, mock_engine_class: Mock, mock_generate: Mock,
        mock_summary: Mock, mock_save: Mock, mock_display: Mock
    ) -> None:
        """Test that sample data is generated."""
        mock_engine = Mock()
        mock_engine_class.return_value = mock_engine
        mock_engine.get_trend_summary.return_value = {}
        mock_generate.return_value = ["metric1"]
        mock_summary.return_value = {}

        analytics.handle_predictive_analytics(
            predictive_analytics=True, prediction_periods=5, analytics_dashboard=None
        )

        mock_generate.assert_called_once_with(mock_engine)

    @patch("crackerjack.cli.handlers.analytics.display_trend_analysis")
    @patch("crackerjack.cli.handlers.analytics.save_analytics_dashboard")
    @patch("crackerjack.cli.handlers.analytics.generate_predictions_summary")
    @patch("crackerjack.cli.handlers.analytics.generate_predictive_sample_data")
    @patch("crackerjack.services.ai.predictive_analytics.PredictiveAnalyticsEngine")
    def test_generates_predictions_summary(
        self, mock_engine_class: Mock, mock_generate: Mock,
        mock_summary: Mock, mock_save: Mock, mock_display: Mock
    ) -> None:
        """Test that predictions summary is generated."""
        mock_engine = Mock()
        mock_engine_class.return_value = mock_engine
        mock_engine.get_trend_summary.return_value = {}
        mock_generate.return_value = ["metric1"]
        mock_summary.return_value = {}

        analytics.handle_predictive_analytics(
            predictive_analytics=True, prediction_periods=5, analytics_dashboard=None
        )

        mock_summary.assert_called_once()

    @patch("crackerjack.cli.handlers.analytics.display_trend_analysis")
    @patch("crackerjack.cli.handlers.analytics.save_analytics_dashboard")
    @patch("crackerjack.cli.handlers.analytics.generate_predictions_summary")
    @patch("crackerjack.cli.handlers.analytics.generate_predictive_sample_data")
    @patch("crackerjack.services.ai.predictive_analytics.PredictiveAnalyticsEngine")
    def test_saves_dashboard_when_path_provided(
        self, mock_engine_class: Mock, mock_generate: Mock,
        mock_summary: Mock, mock_save: Mock, mock_display: Mock
    ) -> None:
        """Test that dashboard is saved when path is provided."""
        mock_engine = Mock()
        mock_engine_class.return_value = mock_engine
        mock_engine.get_trend_summary.return_value = {}
        mock_generate.return_value = ["metric1"]
        mock_summary.return_value = {}

        analytics.handle_predictive_analytics(
            predictive_analytics=True, prediction_periods=5, analytics_dashboard="dashboard.json"
        )

        mock_save.assert_called_once()
