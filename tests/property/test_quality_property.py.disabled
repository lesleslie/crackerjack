"""Property-based tests for quality systems using Hypothesis."""

from pathlib import Path

from hypothesis import given, settings
from hypothesis import strategies as st

from crackerjack.models.qa_config import QACheckConfig, QAOrchestratorConfig
from crackerjack.models.qa_results import QAResult, QAResultStatus
from crackerjack.services.quality.qa_orchestrator import QAOrchestrator


class TestQAConfigProperties:
    """Property-based tests for QA configuration."""

    @given(
        check_name=st.text(min_size=1, max_size=50),
        enabled=st.booleans(),
        is_formatter=st.booleans(),
        timeout=st.integers(min_value=1, max_value=3600),
    )
    def test_qa_check_config_creation(self, check_name, enabled, is_formatter, timeout):
        """Test QACheckConfig can be created with various parameters."""
        config = QACheckConfig(
            check_name=check_name,
            enabled=enabled,
            is_formatter=is_formatter,
            timeout_seconds=timeout,
        )
        assert config.check_name == check_name
        assert config.enabled == enabled
        assert config.is_formatter == is_formatter
        assert config.timeout_seconds == timeout

    @given(
        max_parallel=st.integers(min_value=1, max_value=16),
        fail_fast=st.booleans(),
        run_formatters_first=st.booleans(),
    )
    def test_qa_orchestrator_config_creation(self, max_parallel, fail_fast, run_formatters_first):
        """Test QAOrchestratorConfig with various parameters."""
        config = QAOrchestratorConfig(
            max_parallel_checks=max_parallel,
            fail_fast=fail_fast,
            run_formatters_first=run_formatters_first,
        )
        assert config.max_parallel_checks == max_parallel
        assert config.fail_fast == fail_fast
        assert config.run_formatters_first == run_formatters_first

    @given(
        st.lists(
            st.builds(
                QACheckConfig,
                check_name=st.text(min_size=1, max_size=30, alphabet=st.ascii_letters),
                enabled=st.booleans(),
                is_formatter=st.booleans(),
                timeout_seconds=st.integers(min_value=1, max_value=300),
            ),
            min_size=0,
            max_size=10,
        )
    )
    def test_qa_orchestrator_with_multiple_checks(self, checks):
        """Test QAOrchestrator can handle various numbers of checks."""
        config = QAOrchestratorConfig(fast_checks=checks, comprehensive_checks=[])
        orchestrator = QAOrchestrator(config=config)
        assert len(orchestrator.config.fast_checks) == len(checks)


class TestQAResultProperties:
    """Property-based tests for QA results."""

    @given(
        check_name=st.text(min_size=1, max_size=50),
        status=st.sampled_from(
            [QAResultStatus.PASSED, QAResultStatus.FAILED, QAResultStatus.SKIPPED, QAResultStatus.ERROR]
        ),
        duration=st.floats(min_value=0.0, max_value=3600.0),
        output=st.text(min_size=0, max_size=1000),
    )
    def test_qa_result_creation(self, check_name, status, duration, output):
        """Test QAResult can be created with various parameters."""
        result = QAResult(
            check_name=check_name,
            status=status,
            duration_seconds=duration,
            output=output,
            files_checked=[],
            issues_found=[],
        )
        assert result.check_name == check_name
        assert result.status == status
        assert result.duration_seconds == duration
        assert result.output == output

    @given(
        st.lists(
            st.builds(
                QAResult,
                check_name=st.text(min_size=1, max_size=30, alphabet=st.ascii_letters),
                status=st.sampled_from([QAResultStatus.PASSED, QAResultStatus.FAILED]),
                duration_seconds=st.floats(min_value=0.0, max_value=100.0),
                output=st.text(),
                files_checked=st.just([]),
                issues_found=st.just([]),
            ),
            min_size=0,
            max_size=20,
        )
    )
    def test_qa_results_list_properties(self, results):
        """Test properties of QA results lists."""
        # All results should have valid duration
        for result in results:
            assert result.duration_seconds >= 0.0

        # Count passed and failed
        passed_count = sum(1 for r in results if r.status == QAResultStatus.PASSED)
        failed_count = sum(1 for r in results if r.status == QAResultStatus.FAILED)

        assert passed_count + failed_count == len(results)


class TestQAMetricsCalculation:
    """Property-based tests for metrics calculations."""

    @given(
        st.lists(
            st.builds(
                QAResult,
                check_name=st.text(min_size=1, alphabet=st.ascii_lowercase),
                status=st.sampled_from([QAResultStatus.PASSED, QAResultStatus.FAILED]),
                duration_seconds=st.floats(min_value=0.1, max_value=10.0),
                output=st.text(),
                files_checked=st.just([]),
                issues_found=st.lists(st.text(min_size=1), min_size=0, max_size=10),
            ),
            min_size=1,
            max_size=50,
        )
    )
    def test_success_rate_calculation(self, results):
        """Test success rate is always between 0 and 1."""
        passed = sum(1 for r in results if r.status == QAResultStatus.PASSED)
        total = len(results)
        success_rate = passed / total if total > 0 else 0
        assert 0.0 <= success_rate <= 1.0

    @given(
        st.lists(
            st.builds(
                QAResult,
                check_name=st.text(),
                status=st.just(QAResultStatus.PASSED),
                duration_seconds=st.floats(min_value=0.0, max_value=100.0),
                output=st.text(),
                files_checked=st.just([]),
                issues_found=st.just([]),
            ),
            min_size=1,
            max_size=20,
        )
    )
    def test_total_duration_calculation(self, results):
        """Test total duration is sum of individual durations."""
        total_duration = sum(r.duration_seconds for r in results)
        expected_duration = sum(r.duration_seconds for r in results)
        assert total_duration == expected_duration
        assert total_duration >= 0.0

    @given(
        st.lists(
            st.builds(
                QAResult,
                check_name=st.text(),
                status=st.just(QAResultStatus.FAILED),
                duration_seconds=st.floats(min_value=0.0, max_value=10.0),
                output=st.text(),
                files_checked=st.just([]),
                issues_found=st.lists(st.text(min_size=1), min_size=0, max_size=5),
            ),
            min_size=1,
            max_size=15,
        )
    )
    def test_total_issues_calculation(self, results):
        """Test total issues is sum of individual issues."""
        total_issues = sum(len(r.issues_found) for r in results)
        expected_issues = sum(len(r.issues_found) for r in results)
        assert total_issues == expected_issues
        assert total_issues >= 0


class TestQAConfigFiltering:
    """Property-based tests for configuration filtering."""

    @given(
        st.lists(
            st.builds(
                QACheckConfig,
                check_name=st.text(min_size=1, alphabet=st.ascii_lowercase),
                enabled=st.booleans(),
                is_formatter=st.booleans(),
                timeout_seconds=st.integers(min_value=1, max_value=300),
            ),
            min_size=0,
            max_size=20,
        )
    )
    def test_filter_enabled_checks(self, checks):
        """Test filtering enabled checks."""
        enabled_checks = [c for c in checks if c.enabled]
        assert all(c.enabled for c in enabled_checks)
        assert len(enabled_checks) <= len(checks)

    @given(
        st.lists(
            st.builds(
                QACheckConfig,
                check_name=st.text(min_size=1, alphabet=st.ascii_lowercase),
                enabled=st.just(True),
                is_formatter=st.booleans(),
                timeout_seconds=st.integers(min_value=1, max_value=300),
            ),
            min_size=0,
            max_size=15,
        )
    )
    def test_filter_formatter_checks(self, checks):
        """Test filtering formatter checks."""
        formatters = [c for c in checks if c.is_formatter]
        linters = [c for c in checks if not c.is_formatter]
        assert all(c.is_formatter for c in formatters)
        assert all(not c.is_formatter for c in linters)
        assert len(formatters) + len(linters) == len(checks)


class TestQAOrchestratorProperties:
    """Property-based tests for QA Orchestrator."""

    @given(
        st.lists(
            st.builds(
                QACheckConfig,
                check_name=st.text(min_size=1, max_size=30, alphabet=st.ascii_letters),
                enabled=st.booleans(),
                is_formatter=st.booleans(),
                timeout_seconds=st.integers(min_value=1, max_value=300),
            ),
            min_size=0,
            max_size=10,
        )
    )
    def test_orchestrator_initialization_with_various_configs(self, fast_checks):
        """Test orchestrator initializes with various configurations."""
        config = QAOrchestratorConfig(
            fast_checks=fast_checks,
            comprehensive_checks=[],
            max_parallel_checks=max(1, len(fast_checks)),
        )
        orchestrator = QAOrchestrator(config=config)
        assert orchestrator.config == config
        assert isinstance(orchestrator._adapters, dict)
        assert isinstance(orchestrator._cache, dict)

    @given(
        st.integers(min_value=1, max_value=16),
        st.integers(min_value=0, max_value=10),
    )
    def test_semaphore_value_matches_parallel_limit(self, max_parallel, num_checks):
        """Test semaphore value matches max_parallel_checks."""
        config = QAOrchestratorConfig(
            fast_checks=[],
            comprehensive_checks=[],
            max_parallel_checks=max_parallel,
        )
        orchestrator = QAOrchestrator(config=config)
        assert orchestrator._semaphore._value == max_parallel


class TestQAResultStatusProperties:
    """Property-based tests for QA result status."""

    @given(
        st.lists(
            st.sampled_from(
                [QAResultStatus.PASSED, QAResultStatus.FAILED, QAResultStatus.SKIPPED, QAResultStatus.ERROR]
            ),
            min_size=1,
            max_size=20,
        )
    )
    def test_status_always_valid(self, statuses):
        """Test all statuses are valid enum values."""
        valid_statuses = {
            QAResultStatus.PASSED,
            QAResultStatus.FAILED,
            QAResultStatus.SKIPPED,
            QAResultStatus.ERROR,
        }
        assert all(status in valid_statuses for status in statuses)

    @given(
        st.lists(
            st.sampled_from([QAResultStatus.PASSED, QAResultStatus.FAILED]),
            min_size=0,
            max_size=30,
        )
    )
    def test_passed_plus_failed_equals_total(self, statuses):
        """Test that passed + failed equals total for non-skipped/error results."""
        passed = sum(1 for s in statuses if s == QAResultStatus.PASSED)
        failed = sum(1 for s in statuses if s == QAResultStatus.FAILED)
        assert passed + failed == len(statuses)


class TestQAFilePathProperties:
    """Property-based tests for file path handling."""

    @given(
        st.lists(
            st.from_regex(r"[a-zA-Z0-9_/-]+\.(py|yaml|yml|json|toml|md)", fullmatch=True),
            min_size=0,
            max_size=20,
        )
    )
    def test_file_paths_are_valid(self, path_strings):
        """Test file paths can be converted to Path objects."""
        paths = [Path(p) for p in path_strings]
        assert all(isinstance(p, Path) for p in paths)
        assert all(len(p.name) > 0 for p in paths if str(p) != ".")


class TestQATimeoutProperties:
    """Property-based tests for timeout configurations."""

    @given(
        st.integers(min_value=1, max_value=3600),
        st.integers(min_value=1, max_value=3600),
    )
    def test_timeout_sum_within_bounds(self, timeout1, timeout2):
        """Test sum of timeouts is within reasonable bounds."""
        total_timeout = timeout1 + timeout2
        assert 2 <= total_timeout <= 7200  # 2 seconds to 2 hours

    @given(
        st.lists(
            st.integers(min_value=1, max_value=300),
            min_size=1,
            max_size=20,
        )
    )
    def test_average_timeout_calculation(self, timeouts):
        """Test average timeout calculation."""
        avg_timeout = sum(timeouts) / len(timeouts)
        assert 1 <= avg_timeout <= 300


class TestQAIssueProperties:
    """Property-based tests for issue tracking."""

    @given(
        st.lists(
            st.text(min_size=1, max_size=200, alphabet=st.printable_ascii),
            min_size=0,
            max_size=50,
        )
    )
    def test_issue_list_properties(self, issues):
        """Test properties of issue lists."""
        assert isinstance(issues, list)
        assert all(isinstance(issue, str) for issue in issues)
        assert len(issues) <= 50


class TestQACheckOrdering:
    """Property-based tests for check ordering."""

    @given(
        st.lists(
            st.builds(
                QACheckConfig,
                check_name=st.text(min_size=1, alphabet=st.ascii_lowercase),
                enabled=st.just(True),
                is_formatter=st.booleans(),
                timeout_seconds=st.integers(min_value=1, max_value=100),
            ),
            min_size=0,
            max_size=15,
        )
    )
    def test_formatter_ordering_property(self, checks):
        """Test that formatters come before linters when sorted."""
        # Formatters have is_formatter=True, which sorts as False (0) before True (1)
        sorted_checks = sorted(checks, key=lambda c: (not c.is_formatter, c.check_name))
        for i in range(len(sorted_checks) - 1):
            current_is_formatter = sorted_checks[i].is_formatter
            next_is_formatter = sorted_checks[i + 1].is_formatter
            # If current is not formatter and next is formatter, ordering is violated
            # False (formatter) should come before True (linter)
            assert not (not current_is_formatter and next_is_formatter)


class TestQACacheProperties:
    """Property-based tests for caching."""

    @given(
        st.text(min_size=1, max_size=50, alphabet=st.ascii_letters),
        st.floats(min_value=0.0, max_value=1000.0),
    )
    def test_cache_key_format(self, check_name, duration):
        """Test cache key can be generated from check parameters."""
        # Cache keys typically include check name and parameters
        cache_key = f"{check_name}_{duration}"
        assert isinstance(cache_key, str)
        assert len(cache_key) > 0
