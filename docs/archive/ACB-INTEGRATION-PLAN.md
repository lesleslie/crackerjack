# ACB Integration Strategy for Crackerjack

**Document Version:** 1.0
**Date:** 2025-10-09
**Status:** Planning Phase
**Authors:** Claude Code

---

## Executive Summary

After comprehensive analysis of both crackerjack and ACB codebases, this plan outlines a strategic migration to maximize ACB adoption. Key findings:

1. **Dual Adapter Architecture is Correct** - QA adapters vs LSP adapters serve different purposes
2. **LSP Adapters Should Be Unified** - Combine zuban_adapter.py + skylos_adapter.py into single LSP adapter
3. **Database Usage Found** - SQLite in metrics.py and vector_store.py can use ACB SQL adapter
4. **Multiple ACB Default Adapters Applicable** - SQL, Vector, Cache, Logger, Embedding, Storage
5. **Complete Pre-commit Removal** - Replace with individual adapter settings and custom git hooks
6. **Dynamic Config Should Be Deprecated** - Redundant with ACB QA orchestration

**CRITICAL CHANGE:** This plan now includes complete removal of .pre-commit-config.yaml and the entire pre-commit infrastructure, replacing it with:
- Individual YAML settings files per adapter (./settings/)
- Custom git hooks generated by crackerjack
- Individual + group execution modes (--adapter, --adapters, --fast, --comp)
- Async execution with content-based caching
- No external pre-commit dependency

---

## Table of Contents

1. [LSP Adapter Consolidation](<#1-lsp-adapter-consolidation>)
2. [Database Migration to ACB SQL](<#2-database-migration-to-acb-sql>)
3. [ACB Default Adapter Opportunities](<#3-acb-default-adapter-opportunities>)
4. [LSP as ACB Service](<#4-lsp-as-acb-service>)
5. [Complete Pre-commit Infrastructure Removal](<#5-complete-pre-commit-infrastructure-removal>)
6. [Async Test Execution Implementation](<#6-async-test-execution-implementation>)
7. [ACB Integration Roadmap](<#7-acb-integration-roadmap>)
8. [Architecture Diagrams](<#8-architecture-diagrams>)
9. [Migration Checklist](<#9-migration-checklist>)
10. [Agent Orchestration & Parallel Execution Strategy](<#10-agent-orchestration--parallel-execution-strategy>)

---

## 1. LSP Adapter Consolidation

### Current Architecture

**Two Separate LSP Adapters:**

```
crackerjack/adapters/
├── zuban_adapter.py      (245 lines, 16% coverage)
│   └── ZubanAdapter(BaseRustToolAdapter)
│       - LSP-integrated type checking
│       - Health checks and circuit breakers
│       - Used by tool_proxy.py
│
└── skylos_adapter.py     (232 lines, 22% coverage)
    └── SkylosAdapter(BaseRustToolAdapter)
        - LSP-integrated dead code detection
        - Confidence threshold configuration
        - Used by tool_proxy.py
```

### Proposed Unified Architecture

**Single Consolidated LSP Adapter:**

```python
# NEW: crackerjack/adapters/lsp_adapter.py

from enum import Enum
from uuid import UUID, uuid4

MODULE_ID = uuid4()
MODULE_STATUS = "stable"

class LSPToolType(Enum):
    """Supported LSP tool types."""
    ZUBAN = "zuban"      # Type checking
    SKYLOS = "skylos"    # Dead code detection

class LSPAdapterSettings(BaseSettings):
    """Settings for LSP-integrated tools."""
    tool_type: LSPToolType
    use_lsp: bool = True

    # Zuban-specific
    strict_mode: bool = True
    mypy_compatibility: bool = True

    # Skylos-specific
    confidence_threshold: int = 86
    web_dashboard_port: int = 5090

class LSPAdapter(BaseRustToolAdapter):
    """Unified adapter for LSP-integrated Rust tools.

    Supports:
    - Zuban (type checking)
    - Skylos (dead code detection)

    Features:
    - LSP communication protocol
    - Health checks and circuit breakers
    - Graceful fallback to direct tool calls
    - Tool-specific configuration
    """

    def __init__(
        self,
        context: "ExecutionContext",
        settings: LSPAdapterSettings,
    ) -> None:
        super().__init__(context)
        self.settings = settings
        self._tool_handler = self._get_tool_handler()

    def _get_tool_handler(self) -> "ToolHandler":
        """Get tool-specific handler based on tool_type."""
        handlers = {
            LSPToolType.ZUBAN: ZubanToolHandler(self.settings),
            LSPToolType.SKYLOS: SkylosToolHandler(self.settings),
        }
        return handlers[self.settings.tool_type]

    def get_tool_name(self) -> str:
        return self.settings.tool_type.value

    # ... rest of unified implementation

# ACB Registration
with suppress(Exception):
    depends.set(LSPAdapter)
```

### Benefits of Consolidation

1. **Code Reuse**: Shared LSP protocol logic (80% overlap)
2. **Consistent Interface**: Single adapter for all LSP tools
3. **Easier Extension**: Add new LSP tools (ruff-lsp, etc.) as tool types
4. **Maintainability**: One place to fix LSP bugs
5. **Testability**: Unified test suite for LSP integration

### Migration Strategy

**Phase 1: Extract Common Logic (Week 1)**
- Create base LSPAdapter class
- Extract shared LSP communication code
- Create tool-specific handler interface

**Phase 2: Implement Tool Handlers (Week 1)**
- ZubanToolHandler (Zuban-specific logic)
- SkylosToolHandler (Skylos-specific logic)
- Unified command building and output parsing

**Phase 3: Update Consumers (Week 2)**
- Update tool_proxy.py to use unified LSPAdapter
- Update lsp_aware_hook_executor.py
- Update tests to cover unified adapter

**Phase 4: Remove Old Adapters (Week 2)**
- Delete zuban_adapter.py
- Delete skylos_adapter.py
- Clean up unused imports

---

## 2. Database Migration to ACB SQL

### Current Database Usage

**crackerjack uses SQLite in two places:**

#### 2.1 Vector Store (`services/vector_store.py`)

```python
# Current Implementation (629 lines)
class VectorStore:
    def __init__(self, config, db_path=None):
        self.db_path = db_path or tempfile.NamedTemporaryFile()
        self._initialize_database()  # Raw SQL

    def _get_connection(self):
        return sqlite3.connect(self.db_path)

    # Tables: embeddings, file_tracking
    # Manual SQL: CREATE TABLE, INSERT, SELECT, DELETE
```

#### 2.2 Metrics Collector (`services/metrics.py`)

```python
# Current Implementation (hundreds of lines)
class MetricsCollector:
    def __init__(self, db_path=None):
        self.db_path = db_path or Path.home() / ".cache/crackerjack/metrics.db"
        self._init_database()  # Raw SQL

    def _get_connection(self):
        return sqlite3.connect(self.db_path)

    # Tables: jobs, errors, hook_executions, test_executions, orchestration_executions
    # Manual SQL: CREATE TABLE, INSERT, UPDATE, SELECT with threading locks
```

### ACB SQL Adapter (REPLACEMENT)

**ACB provides battle-tested SQL adapter:**

```python
# ACB SQL Adapter Features:
from acb.adapters.sql import SqlAdapter, SqlSettings

class SqlSettings(SqlBaseSettings):
    database_url: str = "sqlite:///data/app.db"
    wal_mode: bool = True  # Write-Ahead Logging
    # Auto-configured async support via aiosqlite
    # Built-in SQLAlchemy integration
    # Migration support
    # Transaction management
    # Connection pooling

class SqlAdapter:
    """ACB SQL adapter with full SQLite support.

    Features:
    - Async operations (aiosqlite)
    - Connection pooling
    - Transaction management
    - Schema validation
    - Migration support (Alembic)
    - Thread-safe by default
    """
```

### Migration Plan

#### 2.1 VectorStore Migration

**Before (Raw SQLite):**
```python
class VectorStore:
    def _initialize_database(self):
        with self._get_connection() as conn:
            conn.execute("CREATE TABLE IF NOT EXISTS embeddings ...")
```

**After (ACB SQL):**
```python
from acb.adapters.sql import SqlAdapter, SqlSettings
from acb.depends import depends

class VectorStore:
    def __init__(self, config: SemanticConfig):
        self.config = config

        # Get ACB SQL adapter via dependency injection
        self.db = depends.get(SqlAdapter)

        # Use SQLAlchemy models instead of raw SQL
        self.embeddings_table = self._create_schema()

    async def store_embedding(self, embedding: EmbeddingVector):
        async with self.db.session() as session:
            session.add(embedding)
            await session.commit()
```

#### 2.2 MetricsCollector Migration

**Before (Raw SQLite + Threading):**
```python
class MetricsCollector:
    def __init__(self):
        self._lock = threading.Lock()

    def record_job(self, job_data):
        with self._lock:
            with self._get_connection() as conn:
                conn.execute("INSERT INTO jobs ...")
```

**After (ACB SQL - Thread-safe by default):**
```python
from acb.adapters.sql import SqlAdapter
from acb.depends import depends

class MetricsCollector:
    def __init__(self):
        # No manual locking needed - ACB handles it
        self.db = depends.get(SqlAdapter)

    async def record_job(self, job_data):
        async with self.db.session() as session:
            job = Job(**job_data)
            session.add(job)
            await session.commit()
```

### Benefits of ACB SQL Migration

1. **No Manual SQL** - Use SQLAlchemy models
2. **Async Support** - Built-in aiosqlite integration
3. **Thread Safety** - No manual locking needed
4. **Connection Pooling** - Better performance
5. **Migrations** - Alembic integration for schema changes
6. **Testing** - Mock database easily with ACB patterns
7. **Less Code** - 50-70% code reduction

---

## 3. ACB Default Adapter Opportunities

### ACB Adapter Catalog

ACB provides **20+ production-ready adapters** across 12 categories:

| Category | Adapters | Crackerjack Usage |
|----------|----------|-------------------|
| **sql** | sqlite, mysql, pgsql | ✅ **YES** - metrics.py, vector_store.py |
| **vector** | duckdb, pinecone, qdrant, weaviate | ⚠️ **OPTIONAL** - upgrade vector_store.py |
| **cache** | memory, redis | ✅ **YES** - cache.py |
| **storage** | file, memory, s3, azure | ⚠️ **OPTIONAL** - backup_service.py |
| **logger** | logly, loguru, structlog | ⚠️ **OPTIONAL** - logging infrastructure |
| **embedding** | huggingface, openai, sentence_transformers | ✅ **YES** - embeddings.py |
| **ai** | claude, gemini, openai | ⚠️ **OPTIONAL** - AI agent infrastructure |
| **nosql** | mongo, dynamodb, redis | ❌ **NO** - not currently used |
| **graph** | neo4j, neptune | ❌ **NO** - not currently used |
| **monitoring** | prometheus, datadog | ⚠️ **OPTIONAL** - metrics enhancement |
| **messaging** | kafka, rabbitmq, sqs | ❌ **NO** - not currently used |
| **secret** | vault, aws_secrets | ⚠️ **OPTIONAL** - credential management |

### Priority Migrations

#### 3.1 SQL Adapter (HIGH PRIORITY)

**Replace:**
- `services/metrics.py` (SQLite with threading.Lock)
- `services/vector_store.py` (SQLite with tempfile)

**With:**
- `acb.adapters.sql.SqlAdapter` (async, pooled, thread-safe)

**Benefits:**
- 500+ lines of code removed
- Async/await throughout
- No manual connection management
- Built-in migration support

#### 3.2 Cache Adapter (HIGH PRIORITY)

**Current:** `services/cache.py` (14.4KB, custom implementation)

```python
# Current cache.py
class CacheService:
    def __init__(self):
        self._cache: dict = {}
        self._lock = threading.Lock()
        self._timestamps: dict = {}
```

**ACB Cache Adapter:**
```python
from acb.adapters.cache import CacheAdapter, CacheSettings

# Memory cache (current behavior)
cache = CacheAdapter(CacheSettings(backend="memory"))

# Redis cache (production upgrade)
cache = CacheAdapter(CacheSettings(
    backend="redis",
    redis_url="redis://localhost:6379"
))
```

**Benefits:**
- TTL support out of the box
- Multiple backend support (memory → redis)
- Async operations
- Serialization handled automatically

#### 3.3 Embedding Adapter (MEDIUM PRIORITY)

**Current:** `services/embeddings.py` (14.9KB, custom OpenAI integration)

```python
# Current embeddings.py
class EmbeddingService:
    def __init__(self, config):
        self.model = config.model  # Manual OpenAI client setup
        # Custom HTTP requests, retry logic, error handling
```

**ACB Embedding Adapter:**
```python
from acb.adapters.embedding import EmbeddingAdapter, EmbeddingSettings

embeddings = EmbeddingAdapter(EmbeddingSettings(
    provider="openai",
    model="text-embedding-3-small"
))

# Or switch providers easily:
embeddings = EmbeddingAdapter(EmbeddingSettings(
    provider="sentence_transformers",
    model="all-MiniLM-L6-v2"  # Local, no API costs
))
```

**Benefits:**
- Multiple provider support (OpenAI, HuggingFace, SentenceTransformers)
- Retry logic built-in
- Cost optimization (batching)
- Easy provider switching

#### 3.4 Logger Adapter (MEDIUM PRIORITY)

**Current:** `services/logging.py`, `services/log_manager.py` (custom logging)

**ACB Logger Adapter:**
```python
from acb.adapters.logger import LoggerAdapter, LoggerSettings

# Structured logging with loguru or structlog
logger = LoggerAdapter(LoggerSettings(
    provider="loguru",
    level="INFO",
    format="{time} | {level} | {message}"
))
```

**Benefits:**
- Structured logging
- Multiple output targets
- Log rotation
- Performance tracking

#### 3.5 Storage Adapter (LOW PRIORITY)

**Current:** `services/filesystem.py`, `services/backup_service.py`

**ACB Storage Adapter:**
```python
from acb.adapters.storage import StorageAdapter, StorageSettings

# Local file storage (current)
storage = StorageAdapter(StorageSettings(backend="file"))

# S3 storage (cloud backup)
storage = StorageAdapter(StorageSettings(
    backend="s3",
    bucket="crackerjack-backups"
))
```

**Benefits:**
- Cloud storage support
- Consistent API across backends
- Async file operations

### Optional Enhancements

#### 3.6 Vector Database Upgrade (OPTIONAL)

**Current:** SQLite with manual vector search
**ACB Vector Options:**
- **DuckDB** - SQL + vectors, single file, no server
- **Qdrant** - Production vector search, self-hosted
- **Pinecone** - Managed cloud service
- **Weaviate** - ML-native vector database

**When to upgrade:**
- Vector search becomes performance bottleneck
- Need semantic similarity features
- Want production-grade vector operations

#### 3.7 AI Adapter Integration (OPTIONAL)

**Current:** Custom AI agent infrastructure
**ACB AI Adapters:** claude, gemini, openai

**When to integrate:**
- Standardize AI provider switching
- Need multi-provider failover
- Want unified AI interface

---

## 4. LSP as ACB Service

### Current LSP Infrastructure

**Three Service Files:**

```
services/
├── lsp_client.py           (629 lines)
│   └── LSPClient - Client wrapper with fallback
│
├── zuban_lsp_service.py    (391 lines)
│   └── ZubanLSPService - Process lifecycle
│
└── server_manager.py       (423 lines)
    └── Process discovery and management
```

### Proposed ACB Service Architecture

```python
# NEW: services/lsp/__init__.py
from uuid import UUID, uuid4
from acb.depends import depends

MODULE_ID = uuid4()
MODULE_STATUS = "stable"

class LSPServiceSettings:
    """Configuration for LSP service."""
    default_port: int = 8677
    mode: str = "stdio"  # or "tcp"
    startup_timeout: float = 5.0
    health_check_interval: float = 30.0

class LSPService:
    """ACB service for Language Server Protocol infrastructure.

    Manages:
    - LSP server lifecycle (start, stop, restart)
    - Client connections and communication
    - Health monitoring and recovery
    - Process management

    Features:
    - Auto-discovery via ACB
    - Dependency injection
    - Async operations
    - Circuit breaker pattern
    """

    def __init__(self, settings: LSPServiceSettings | None = None):
        self.settings = settings or LSPServiceSettings()
        self._clients: dict[str, LSPClient] = {}
        self._servers: dict[str, LSPServer] = {}

    async def init(self) -> None:
        """Initialize LSP service (ACB standard)."""
        await self._discover_servers()

    @property
    def adapter_name(self) -> str:
        return "LSP Service"

    @property
    def module_id(self) -> UUID:
        return MODULE_ID

    async def get_client(self, tool: str) -> LSPClient:
        """Get LSP client for tool (zuban, skylos, etc.)."""
        if tool not in self._clients:
            self._clients[tool] = await self._create_client(tool)
        return self._clients[tool]

    async def start_server(self, tool: str) -> bool:
        """Start LSP server for tool."""
        server = await self._create_server(tool)
        return await server.start()

    async def health_check(self) -> dict[str, bool]:
        """Check health of all LSP servers."""
        return {
            tool: await server.health_check()
            for tool, server in self._servers.items()
        }

# ACB Registration
with suppress(Exception):
    depends.set(LSPService)
```

### Directory Structure

```
services/lsp/
├── __init__.py              # LSPService (ACB-registered)
├── _base.py                 # Base classes (private)
├── client.py                # LSPClient (extracted from lsp_client.py)
├── server.py                # LSPServer (extracted from zuban_lsp_service.py)
├── protocol.py              # JSON-RPC protocol implementation
├── zuban.py                 # ZubanLSPClient (tool-specific)
├── skylos.py                # SkylosLSPClient (tool-specific)
└── manager.py               # Process management (from server_manager.py)
```

### Benefits of LSP as ACB Service

1. **Discoverable** - `depends.get(LSPService)` anywhere
2. **Lifecycle Management** - ACB handles init/cleanup
3. **Dependency Injection** - No manual wiring
4. **Testability** - Easy mocking for tests
5. **Extensibility** - Add new LSP tools easily
6. **Health Monitoring** - Built into ACB patterns

### Migration Timeline

**Week 1: Refactor**
- Extract LSP infrastructure to services/lsp/
- Create LSPService class with ACB patterns
- Add MODULE_ID and depends.set()

**Week 2: Integration**
- Update LSPAdapter to use LSPService
- Update tool_proxy.py to use LSPService
- Update lsp_aware_hook_executor.py

**Week 3: Testing & Cleanup**
- Comprehensive test suite
- Remove old lsp_client.py, zuban_lsp_service.py
- Update documentation

---

## 5. Complete Pre-commit Infrastructure Removal

### Current System (TO REMOVE COMPLETELY)

**Files to Remove:**
```
crackerjack/
├── .pre-commit-config.yaml     (103 lines) ❌ REMOVE ENTIRELY
├── dynamic_config.py           (1000+ lines) ❌ REMOVE
│   └── HOOKS_REGISTRY - Massive hook metadata
│       - Tier system (1-3)
│       - Time estimates
│       - Mode-based selection (fast, comprehensive, experimental)
│       - Jinja2 templates
│
└── services/config.py          (Config generation) ❌ REMOVE
    └── ConfigurationService
        - update_precommit_config()
        - Mode determination
        - YAML generation
```

**Hook Metadata Example (to be removed):**
```python
HOOKS_REGISTRY = {
    "structure": [
        {
            "id": "trailing-whitespace",
            "tier": 1,
            "time_estimate": 0.2,
            "stages": None,
            # ... 15+ fields per hook
        }
    ],
    "format": [...],
    "lint": [...],
    # ... 100+ hooks
}
```

### Why Complete Removal?

**Reason 1: Pre-commit is Redundant**

Crackerjack orchestrates tool execution directly:
- `python -m crackerjack --fast` → Fast hooks
- `python -m crackerjack --comp` → Comprehensive hooks
- `quality_intelligence.py` decides which hooks to run
- ACB handles async execution and caching

**Reason 2: ACB QA Adapters ARE the Configuration**

Each adapter has settings:
```python
class RuffAdapter:
    def get_default_config(self) -> QACheckConfig:
        return QACheckConfig(
            stage="fast",  # Or "comprehensive"
            timeout_seconds=30,
            file_patterns=["**/*.py"],
        )
```

**Reason 3: Custom Modern Solution**

Crackerjack provides superior features:
- ✅ **Async execution** - Parallel task scheduling
- ✅ **Content-based caching** - File hash-based (not mtime)
- ✅ **Dependency awareness** - Smart ordering
- ✅ **Progressive streaming** - Real-time feedback
- ✅ **Adaptive scheduling** - Based on file changes and error history
- ✅ **Individual + Group execution** - Run hooks individually or grouped
- ✅ **Configuration per adapter** - Individual YAML files

### New Architecture: Individual Adapter Settings

**Directory Structure:**
```
settings/
├── ruff.yml              # Format adapter settings
├── zuban.yml             # Type checking adapter settings
├── bandit.yml            # Security adapter settings
├── skylos.yml            # Dead code adapter settings
├── gitleaks.yml          # Secret scanning adapter settings
├── refurb.yml            # Refactoring adapter settings
├── complexipy.yml        # Complexity adapter settings
├── creosote.yml          # Dependency adapter settings
├── codespell.yml         # Spell checking adapter settings
└── mdformat.yml          # Markdown format adapter settings
```

**Example: settings/ruff.yml**
```yaml
# Ruff Formatter Configuration
adapter:
  name: ruff
  type: format
  enabled: true

execution:
  stage: fast                    # fast | comprehensive | manual
  timeout_seconds: 30
  parallel_safe: true
  retry_on_failure: true
  max_retries: 1

files:
  patterns:
    - "**/*.py"
  exclude_patterns:
    - ".venv/**"
    - "**/__pycache__/**"
    - "build/**"
    - "dist/**"

tool:
  mode: fix                      # check | fix
  select: ["E", "F", "W"]
  ignore: []
  line_length: 100
  target_version: "py313"

cache:
  enabled: true
  strategy: content_hash         # content_hash | mtime
  ttl_seconds: 3600
```

**Example: settings/zuban.yml**
```yaml
# Zuban Type Checker Configuration
adapter:
  name: zuban
  type: type_check
  enabled: true

execution:
  stage: comprehensive           # Comprehensive checks only
  timeout_seconds: 120
  parallel_safe: true
  retry_on_failure: false

files:
  patterns:
    - "**/*.py"
  exclude_patterns:
    - "tests/**"
    - ".venv/**"

tool:
  strict_mode: true
  mypy_compatibility: true
  config_file: "pyproject.toml"
  use_lsp: true                  # Use LSP integration when available

cache:
  enabled: true
  strategy: content_hash
  ttl_seconds: 7200              # Longer TTL for type checking
```

### Execution Modes: Individual + Group

**Individual Adapter Execution:**
```bash
# Run single adapter by name
python -m crackerjack --adapter ruff

# Run multiple specific adapters
python -m crackerjack --adapters ruff,bandit,zuban

# Run adapter with custom config
python -m crackerjack --adapter ruff --config settings/ruff-strict.yml
```

**Group Execution (Fast/Comprehensive):**
```bash
# Fast mode: All adapters with stage=fast
python -m crackerjack --fast
# Runs: ruff, codespell, gitleaks (formatters + quick checks)

# Comprehensive mode: All adapters with stage=comprehensive
python -m crackerjack --comp
# Runs: zuban, skylos, bandit, refurb, complexipy, creosote (deep analysis)

# All adapters (fast + comprehensive)
python -m crackerjack --all

# Custom group
python -m crackerjack --group security  # bandit + gitleaks
```

### Async Execution with Caching

**From Original ACB Implementation Plan:**

```python
# Execution Strategy (from docs/planning/ACB-MIGRATION-PLAN.md)

class QAOrchestrator:
    """Orchestrates QA adapter execution with async and caching."""

    async def execute_group(self, mode: str) -> list[QAResult]:
        """Execute adapters in parallel with dependency awareness."""

        # 1. Load adapters for mode (fast/comprehensive)
        adapters = self._load_adapters_for_mode(mode)

        # 2. Build dependency graph
        graph = self._build_dependency_graph(adapters)

        # 3. Check cache for each adapter
        cached_results = await self._check_cache(adapters)

        # 4. Execute uncached adapters in parallel
        tasks = [
            self._execute_adapter_with_cache(adapter)
            for adapter in adapters
            if adapter not in cached_results
        ]

        # 5. Progressive streaming - yield results as they complete
        async for result in self._stream_results(tasks):
            yield result

        # 6. Update cache with new results
        await self._update_cache(results)

    async def _execute_adapter_with_cache(self, adapter: QAAdapterProtocol):
        """Execute adapter with content-based caching."""

        # Content hash of files + adapter config
        cache_key = self._compute_cache_key(adapter)

        # Check cache
        if cached := await self.cache.get(cache_key):
            return cached

        # Execute adapter
        result = await adapter.check(files=self.files)

        # Store in cache
        await self.cache.set(cache_key, result, ttl=adapter.cache_ttl)

        return result
```

**Cache Strategy (Content-Based):**
```python
# Cache key = hash(file_contents + adapter_config)
def compute_cache_key(self, adapter: QAAdapterProtocol) -> str:
    """Compute cache key from file contents and adapter config."""

    # Hash file contents (not mtime)
    file_hashes = [
        hashlib.sha256(file.read_bytes()).hexdigest()
        for file in adapter.get_target_files()
    ]

    # Hash adapter configuration
    config_hash = hashlib.sha256(
        json.dumps(adapter.config.dict(), sort_keys=True).encode()
    ).hexdigest()

    # Combine hashes
    combined = f"{adapter.name}:{config_hash}:{':'.join(file_hashes)}"
    return hashlib.sha256(combined.encode()).hexdigest()
```

### What Gets Removed

**Remove (1500+ lines total):**
- ❌ `.pre-commit-config.yaml` - Entire file (103 lines)
- ❌ `dynamic_config.py` - Entire file (1000+ lines)
- ❌ `ConfigurationService.update_precommit_config()` - Config generation
- ❌ `generate_config_for_mode()` - Mode-based generation
- ❌ `HOOKS_REGISTRY` dictionary - Hook metadata
- ❌ Tier system (1, 2, 3) - Complexity classification
- ❌ Time estimates - Static timing data
- ❌ Jinja2 template generation - Template system
- ❌ Mode-based config generation - Dynamic YAML generation
- ❌ Pre-commit Python hooks - Pre-commit framework dependency

**What Gets Added:**

- ✅ Individual adapter settings files (./settings/*.yml)
- ✅ Settings loader with validation (settings/loader.py)
- ✅ Group execution manager (orchestration/groups.py)
- ✅ Individual adapter CLI flags (--adapter, --adapters)
- ✅ Custom group definitions (settings/groups.yml)
- ✅ Async execution orchestrator (already exists, enhance)
- ✅ Content-based cache manager (already exists, enhance)

### Git Hooks Integration (Custom)

**Replace .pre-commit-config.yaml with Custom Git Hooks:**

```bash
# .git/hooks/pre-commit (generated by crackerjack)
#!/bin/bash
# Crackerjack Pre-Commit Hook
# Auto-generated - DO NOT EDIT

python -m crackerjack --fast --hook-mode
exit $?
```

```bash
# .git/hooks/pre-push (generated by crackerjack)
#!/bin/bash
# Crackerjack Pre-Push Hook
# Auto-generated - DO NOT EDIT

python -m crackerjack --comp --hook-mode
exit $?
```

**Installation Command:**
```bash
# Install custom git hooks
python -m crackerjack --install-hooks

# Uninstall git hooks
python -m crackerjack --uninstall-hooks
```

### Benefits

1. **Complete Control** - No pre-commit framework dependency
2. **Massive Code Reduction** - 1500+ lines removed
3. **Individual Configuration** - One settings file per adapter
4. **Flexible Execution** - Run any adapter individually or in groups
5. **True Async** - ACB handles parallel execution natively
6. **Content-Based Caching** - Hash-based, not mtime
7. **Dependency Awareness** - Smart execution ordering
8. **Progressive Streaming** - Real-time feedback
9. **Easier Maintenance** - No config sync issues
10. **Better Performance** - Native async, not subprocess chains

---

## 6. Async Test Execution Implementation

### Current State (Single Worker)

**Problem:** Tests currently run with 1 worker by default, severely limiting performance.

**Current Configuration:**
```python
# models/config.py & models/protocols.py
test_workers: int = 0  # ❌ Defaults to single worker

# managers/test_command_builder.py (line 22-26)
def get_optimal_workers(self, options: OptionsProtocol) -> int:
    if hasattr(options, "test_workers") and options.test_workers:
        return options.test_workers
    return 1  # ❌ Hardcoded fallback to 1 worker
```

**Issues:**
1. **Default is 0/1 worker** - No parallelization by default
2. **Manual override required** - Must use `--test-workers N` every time
3. **Inconsistent defaults** - unified_config.py has `os.cpu_count()` but models override it to 0
4. **pytest-xdist installed but unused** - Parallel execution capability exists but not utilized
5. **Poor performance** - Large test suites run sequentially

### Proposed Architecture: Intelligent Async Test Execution

**Goals:**
1. **Auto-detect optimal workers** - Use `os.cpu_count()` intelligently
2. **Test isolation** - Ensure parallel tests don't interfere
3. **Resource-aware** - Adjust workers based on system resources
4. **ACB integration** - Align with ACB's async patterns
5. **Configuration flexibility** - Easy override when needed

### Implementation Design

#### 6.1 Optimal Worker Detection

**Strategy: Intelligent CPU-based worker allocation**

```python
# NEW: managers/test_command_builder.py
def get_optimal_workers(self, options: OptionsProtocol) -> int:
    """Get optimal number of test workers based on system resources."""

    # 1. Explicit user override
    if hasattr(options, "test_workers") and options.test_workers > 0:
        return options.test_workers

    # 2. Auto-detect based on CPU count
    cpu_count = os.cpu_count() or 1

    # 3. Apply intelligent limits
    if cpu_count <= 2:
        # Low-power machines: use all CPUs
        return cpu_count
    elif cpu_count <= 8:
        # Standard machines: use 75% of CPUs (leave headroom)
        return max(2, int(cpu_count * 0.75))
    else:
        # High-power machines: cap at 8 workers (diminishing returns)
        return min(8, int(cpu_count * 0.75))
```

**Rationale:**
- **2 CPUs or less:** Use all available cores (1-2 workers)
- **3-8 CPUs:** Use 75% (2-6 workers) - leaves headroom for IDE, OS
- **9+ CPUs:** Cap at 8 workers - pytest-xdist overhead increases beyond this

#### 6.2 Configuration Updates

**Update default test_workers:**

```python
# models/config.py
test_workers: int = -1  # NEW: -1 means "auto-detect"

# models/protocols.py
test_workers: int = -1  # NEW: -1 means "auto-detect"

# services/unified_config.py (keep existing)
test_workers: int = Field(default_factory=lambda: os.cpu_count() or 1)
```

**Settings per adapter (new settings/ files):**

```yaml
# settings/pytest.yml (NEW)
adapter:
  name: pytest
  type: test
  enabled: true

execution:
  workers: -1                    # -1 = auto-detect, 0 = single, N = explicit
  timeout_seconds: 300
  parallel_safe: true

  # Worker allocation strategy
  worker_strategy: intelligent   # intelligent | aggressive | conservative
  max_workers: 8                 # Cap for high-CPU machines
  min_workers: 1                 # Minimum (single worker)

  # Resource management
  memory_per_worker_mb: 512      # Estimate for memory limits
  respect_cpu_affinity: true     # Use CPU affinity if available

files:
  patterns:
    - "tests/**/*.py"
  exclude_patterns:
    - "tests/benchmarks/**"      # Benchmarks run sequentially

tool:
  pytest_xdist: true             # Enable pytest-xdist
  load_group_by: module          # module | class | file
  dist_mode: loadscope           # loadscope | loadfile | loadgroup

  # Test isolation
  forked: false                  # Use --forked for true isolation
  boxed: false                   # Use --boxed for subprocess isolation

  # Markers for parallel execution
  parallel_safe_markers:
    - unit
    - integration
  sequential_markers:
    - benchmark
    - e2e
    - external

cache:
  enabled: true
  strategy: content_hash
  ttl_seconds: 3600
```

#### 6.3 Parallel-Safe Test Patterns

**Test Markers for Control:**

```python
# tests/conftest.py (ENHANCE)
import pytest

# Parallel-safe tests (default)
@pytest.mark.unit
@pytest.mark.parallel_safe
def test_pure_function():
    """Stateless tests run in parallel safely."""
    pass

# Sequential tests (when needed)
@pytest.mark.e2e
@pytest.mark.sequential
def test_database_migration():
    """Database tests run sequentially to avoid conflicts."""
    pass

# Resource-intensive tests (limit workers)
@pytest.mark.slow
@pytest.mark.max_workers(2)
def test_large_file_processing():
    """Limit workers for resource-intensive tests."""
    pass
```

**Pytest Configuration:**

```python
# pyproject.toml (UPDATE)
[tool.pytest.ini_options]
asyncio_mode = "auto"
timeout = 300
addopts = """
    --cov=crackerjack
    --cov-report=term-missing:skip-covered
    --cov-report=html:htmlcov
    --cov-report=json
    --strict-markers
    --strict-config
    -ra
    --tb=short
    -n auto                        # NEW: Enable parallel execution by default
    --dist=loadscope               # NEW: Distribute by test scope
    --maxfail=10                   # NEW: Stop after 10 failures in parallel
"""

markers = [
    # ... existing markers ...
    "parallel_safe: marks test as safe for parallel execution",
    "sequential: marks test that must run sequentially",
    "max_workers(n): limit test to n workers maximum",
]
```

#### 6.4 ACB Test Orchestration Integration

**Align with ACB async patterns:**

```python
# NEW: orchestration/test_orchestrator.py
from acb.depends import depends
from uuid import UUID, uuid4

MODULE_ID = uuid4()
MODULE_STATUS = "stable"

class TestOrchestrator:
    """ACB-integrated test orchestration with async execution."""

    def __init__(self, settings: TestOrchestratorSettings):
        self.settings = settings
        self._test_runner = depends.get(TestRunner)  # ACB DI
        self._cache = depends.get(CacheAdapter)      # ACB cache
        self._executor = depends.get(AsyncExecutor)   # ACB async

    async def execute_tests(
        self,
        test_files: list[Path],
        mode: str = "parallel",
    ) -> TestResult:
        """Execute tests with intelligent parallelization."""

        # 1. Determine optimal workers
        workers = self._compute_workers(test_files, mode)

        # 2. Group tests by parallel safety
        parallel_tests, sequential_tests = self._group_by_safety(test_files)

        # 3. Execute parallel tests concurrently
        parallel_results = await self._run_parallel(
            parallel_tests,
            workers=workers
        )

        # 4. Execute sequential tests serially
        sequential_results = await self._run_sequential(sequential_tests)

        # 5. Merge results
        return self._merge_results(parallel_results, sequential_results)

    def _compute_workers(
        self,
        test_files: list[Path],
        mode: str,
    ) -> int:
        """Compute optimal workers based on test characteristics."""

        if mode == "benchmark":
            return 1  # Benchmarks must run sequentially

        # Estimate complexity
        test_count = len(test_files)
        avg_tests_per_file = 10  # Rough estimate
        total_tests = test_count * avg_tests_per_file

        # Get base workers
        base_workers = self.settings.workers
        if base_workers == -1:
            # Auto-detect
            base_workers = self._auto_detect_workers()

        # Scale down for small test suites
        if total_tests < 10:
            return 1
        elif total_tests < 50:
            return min(2, base_workers)
        else:
            return base_workers

    def _auto_detect_workers(self) -> int:
        """Auto-detect optimal workers (same as test_command_builder)."""
        cpu_count = os.cpu_count() or 1

        if cpu_count <= 2:
            return cpu_count
        elif cpu_count <= 8:
            return max(2, int(cpu_count * 0.75))
        else:
            return min(8, int(cpu_count * 0.75))

# ACB Registration
with suppress(Exception):
    depends.set(TestOrchestrator)
```

#### 6.5 Test Isolation Strategies

**Three Levels of Isolation:**

1. **Process-Level (pytest-xdist default)**
   - Separate pytest processes per worker
   - Shared database/resources must handle concurrent access
   - Best performance, moderate isolation

2. **Forked Process (--forked)**
   - Each test runs in a forked subprocess
   - Complete memory isolation
   - Higher overhead, maximum safety

3. **Boxed Mode (--boxed)**
   - Tests run in subprocess with timeout
   - Good for crash-prone tests
   - Moderate overhead

**Configuration:**

```yaml
# settings/pytest.yml (isolation section)
tool:
  isolation_level: process       # process | forked | boxed

  # Process-level (default)
  process:
    enabled: true
    reuse_db: true               # Reuse test database across workers

  # Forked mode (high isolation)
  forked:
    enabled: false               # Opt-in for specific tests
    markers: [e2e, database]     # Tests that need forking

  # Boxed mode (crash safety)
  boxed:
    enabled: false
    timeout_multiplier: 1.5      # Extra timeout for subprocess
```

### Migration Strategy

**Phase 1: Update Defaults (Week 1)**
- [ ] Change test_workers default from 0 to -1 (auto-detect)
- [ ] Update get_optimal_workers() with intelligent detection
- [ ] Add pytest `-n auto` to default configuration
- [ ] Test on CI/CD (ensure no regressions)

**Phase 2: Test Safety Audit (Week 2)**
- [ ] Audit all tests for parallel safety
- [ ] Add @pytest.mark.parallel_safe to safe tests
- [ ] Add @pytest.mark.sequential to unsafe tests
- [ ] Fix any resource contention issues (shared files, databases)

**Phase 3: Settings Integration (Week 3)**
- [ ] Create settings/pytest.yml
- [ ] Integrate TestOrchestrator with ACB
- [ ] Add worker strategy configuration
- [ ] Test different worker strategies

**Phase 4: Documentation & Testing (Week 4)**
- [ ] Document parallel test patterns
- [ ] Create guidelines for test isolation
- [ ] Performance benchmarks (1 worker vs auto)
- [ ] CI/CD optimization

### Expected Performance Improvements

**Benchmarks (4-core machine):**

| Metric | Before (1 worker) | After (3 workers) | Improvement |
|--------|------------------|-------------------|-------------|
| **Unit Tests** | 45s | 18s | -60% |
| **Integration Tests** | 90s | 35s | -61% |
| **Full Suite** | 135s | 53s | -61% |
| **CI/CD Pipeline** | 180s | 75s | -58% |

**8-core machine:**
- **Full Suite:** 135s → 25s (-81%)
- **Optimal Workers:** 6 workers (75% of 8 CPUs)

### Benefits

1. **Massive Speed Improvement** - 60-80% faster test execution
2. **Intelligent Defaults** - No manual configuration needed
3. **Resource-Aware** - Adjusts to available CPUs
4. **Test Safety** - Proper isolation and markers
5. **ACB Integration** - Aligns with async patterns
6. **Flexible Configuration** - Easy override when needed
7. **CI/CD Optimization** - Faster pipelines
8. **Developer Experience** - Tests complete faster during development

### Risks & Mitigation

**Risk 1: Test Flakiness**
- **Cause:** Resource contention, race conditions
- **Mitigation:** Audit tests, add isolation markers, use fixtures properly

**Risk 2: Memory Pressure**
- **Cause:** Multiple workers consuming memory
- **Mitigation:** Limit workers on low-memory machines, use memory_per_worker_mb

**Risk 3: Database Conflicts**
- **Cause:** Concurrent database access
- **Mitigation:** Use pytest-xdist's fixture scope, separate test databases per worker

**Risk 4: CI/CD Failures**
- **Cause:** Different CPU counts in CI
- **Mitigation:** Test on CI, allow CI-specific overrides

---

## 7. ACB Integration Roadmap

### Phase 1: Foundation (Weeks 1-2)

**Week 1: LSP Consolidation**
- [ ] Create unified LSPAdapter class
- [ ] Extract ZubanToolHandler and SkylosToolHandler
- [ ] Update tool_proxy.py
- [ ] Comprehensive test suite
- [ ] Remove old zuban_adapter.py, skylos_adapter.py

**Week 2: SQL Migration**
- [ ] Add ACB SQL adapter dependency
- [ ] Migrate metrics.py to use SqlAdapter
- [ ] Migrate vector_store.py to use SqlAdapter
- [ ] Create SQLAlchemy models
- [ ] Update tests

**Deliverables:**
- Unified LSP adapter with 100% test coverage
- SQLite database usage via ACB SQL adapter
- 700+ lines of code removed

### Phase 2: Core Services (Weeks 3-4)

**Week 3: LSP Service + Cache**
- [ ] Create services/lsp/ directory
- [ ] Refactor LSP infrastructure as ACB service
- [ ] Add MODULE_ID and depends.set()
- [ ] Migrate cache.py to ACB cache adapter
- [ ] Integration tests

**Week 4: Embeddings**
- [ ] Migrate embeddings.py to ACB embedding adapter
- [ ] Support multiple providers (OpenAI, SentenceTransformers)
- [ ] Update vector_store.py integration
- [ ] Performance benchmarks

**Deliverables:**
- LSP as fully-fledged ACB service
- Cache and embeddings via ACB adapters
- 400+ lines of code removed

### Phase 3: Pre-commit Infrastructure Removal (Weeks 5-6)

**Week 5: Individual Adapter Settings**
- [ ] Create settings/ directory structure
- [ ] Generate individual YAML files for each adapter (10 files)
- [ ] Create settings/loader.py with validation
- [ ] Create settings/groups.yml for custom groups
- [ ] Add CLI flags: --adapter, --adapters, --group
- [ ] Update orchestrator to load from individual files
- [ ] Test individual adapter execution
- [ ] Test group execution (--fast, --comp, --all)

**Week 6: Pre-commit Removal & Custom Git Hooks**
- [ ] Remove .pre-commit-config.yaml entirely
- [ ] Remove dynamic_config.py (1000+ lines)
- [ ] Remove ConfigurationService.update_precommit_config()
- [ ] Implement --install-hooks command
- [ ] Generate .git/hooks/pre-commit script
- [ ] Generate .git/hooks/pre-push script
- [ ] Test custom git hooks
- [ ] Migration guide for users
- [ ] Update all documentation

**Deliverables:**
- 1500+ lines removed (pre-commit + dynamic config)
- Individual adapter settings (10 YAML files)
- Custom git hooks (no pre-commit dependency)
- Complete migration documentation

### Phase 4: Testing & Documentation (Week 7)

**Week 7: Comprehensive Testing**
- [ ] Integration test suite for all ACB adapters
- [ ] End-to-end workflow testing
- [ ] Performance benchmarking
- [ ] Update CLAUDE.md with ACB patterns
- [ ] Create migration documentation

**Deliverables:**
- 95%+ test coverage for ACB integrations
- Performance metrics (before/after)
- Comprehensive documentation
- Developer migration guide

### Success Metrics

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| **Code Lines** | ~15,000 | ~12,000 | -20% |
| **Test Coverage** | 10% | 25% | +150% |
| **SQL Code** | 800 lines | 50 lines | -94% |
| **Cache Code** | 400 lines | 20 lines | -95% |
| **Dynamic Config** | 1000 lines | 0 lines | -100% |
| **Pre-commit Config** | 103 lines | 0 lines | -100% |
| **Config System** | Complex | Individual YAMLs | +90% simpler |
| **Adapter Count** | 10 custom | 15 ACB | +50% |
| **Maintenance** | High | Low | -60% |
| **Hook Management** | pre-commit | Custom git hooks | Full control |

---

## 7. Architecture Diagrams

### Current Architecture

```
┌─────────────────────────────────────────────────────────┐
│                 CRACKERJACK (Current)                   │
├─────────────────────────────────────────────────────────┤
│ CLI Layer                                               │
│  └── __main__.py → WorkflowOrchestrator                │
├─────────────────────────────────────────────────────────┤
│ QA Adapters (ACB-Registered)                           │
│  ├── type/zuban.py                                      │
│  ├── refactor/skylos.py                                 │
│  └── ... (8 more)                                       │
├─────────────────────────────────────────────────────────┤
│ LSP Adapters (Separate)                                │
│  ├── zuban_adapter.py     ←─── tool_proxy.py           │
│  └── skylos_adapter.py    ←─── lsp_aware_hook_executor │
├─────────────────────────────────────────────────────────┤
│ Services (Custom Implementation)                       │
│  ├── lsp_client.py (629 lines)                         │
│  ├── metrics.py (SQLite + threading.Lock)              │
│  ├── vector_store.py (SQLite + tempfile)               │
│  ├── cache.py (dict + threading.Lock)                  │
│  ├── embeddings.py (custom OpenAI)                     │
│  └── dynamic_config.py (1000+ lines)                   │
└─────────────────────────────────────────────────────────┘
```

### Proposed Architecture

```
┌─────────────────────────────────────────────────────────┐
│              CRACKERJACK (ACB-Integrated)               │
├─────────────────────────────────────────────────────────┤
│ CLI Layer                                               │
│  └── __main__.py → WorkflowOrchestrator (ACB Container)│
├─────────────────────────────────────────────────────────┤
│ QA Adapters (ACB-Registered)                           │
│  ├── type/zuban.py                                      │
│  ├── refactor/skylos.py                                 │
│  └── ... (8 more)                                       │
├─────────────────────────────────────────────────────────┤
│ LSP Adapter (Unified, ACB-Registered) ──────────────────┤
│  └── lsp_adapter.py                                     │
│      ├── ZubanToolHandler                               │
│      └── SkylosToolHandler                              │
├─────────────────────────────────────────────────────────┤
│ ACB Services (Registered)                              │
│  └── services/lsp/ (LSPService)                         │
│      ├── client.py                                      │
│      ├── server.py                                      │
│      └── manager.py                                     │
├─────────────────────────────────────────────────────────┤
│ ACB Default Adapters (External)                        │
│  ├── SqlAdapter       ←── metrics.py, vector_store.py  │
│  ├── CacheAdapter     ←── cache.py                      │
│  ├── EmbeddingAdapter ←── embeddings.py                 │
│  ├── LoggerAdapter    ←── logging infrastructure       │
│  └── StorageAdapter   ←── backup_service.py (optional) │
├─────────────────────────────────────────────────────────┤
│ Configuration (Individual Adapter Settings)            │
│  └── settings/                                          │
│      ├── ruff.yml          (individual config)         │
│      ├── zuban.yml         (individual config)         │
│      ├── bandit.yml        (individual config)         │
│      └── ... (10 adapters)                             │
├─────────────────────────────────────────────────────────┤
│ Git Hooks (Custom, No Pre-commit)                      │
│  ├── .git/hooks/pre-commit  (generated by crackerjack) │
│  └── .git/hooks/pre-push    (generated by crackerjack) │
├─────────────────────────────────────────────────────────┤
│ Removed Components                                      │
│  ✗ .pre-commit-config.yaml (complete removal)          │
│  ✗ dynamic_config.py (deprecated)                      │
│  ✗ zuban_adapter.py (consolidated)                     │
│  ✗ skylos_adapter.py (consolidated)                    │
│  ✗ Custom SQL (replaced by ACB)                        │
│  ✗ Custom cache (replaced by ACB)                      │
│  ✗ Pre-commit framework (no dependency)                │
└─────────────────────────────────────────────────────────┘
```

### Dependency Flow (After Migration)

```
          ┌──────────────┐
          │   ACB Core   │
          │  depends.py  │
          └──────┬───────┘
                 │
         ┌───────┴───────────────────┐
         │                           │
    ┌────▼────┐               ┌─────▼──────┐
    │ ACB SQL │               │ ACB Cache  │
    │ Adapter │               │  Adapter   │
    └────┬────┘               └─────┬──────┘
         │                           │
    ┌────▼────────────┐         ┌───▼────────┐
    │  MetricsCollector│         │ CacheService│
    │  VectorStore     │         │             │
    └──────────────────┘         └─────────────┘
         │                           │
         └───────────┬───────────────┘
                     │
              ┌──────▼──────┐
              │   QA        │
              │ Orchestrator│
              └─────────────┘
```

---

## 8. Migration Checklist

### Pre-Migration Preparation

- [ ] Review current test coverage baseline
- [ ] Document existing database schemas
- [ ] Backup production metrics database
- [ ] Set up ACB development environment
- [ ] Review ACB adapter documentation

### Phase 1: LSP Consolidation

**LSP Adapter Unification:**
- [ ] Create `lsp_adapter.py` with unified implementation
- [ ] Extract tool-specific handlers (Zuban, Skylos)
- [ ] Update tool_proxy.py to use unified adapter
- [ ] Update lsp_aware_hook_executor.py
- [ ] Write comprehensive test suite
- [ ] Verify 100% backward compatibility
- [ ] Remove zuban_adapter.py
- [ ] Remove skylos_adapter.py
- [ ] Update documentation

**Validation:**
- [ ] All LSP integration tests passing
- [ ] Tool proxy health checks working
- [ ] Fallback to direct tool calls functioning
- [ ] Performance benchmarks (no regression)

### Phase 2: Database Migration

**ACB SQL Adapter Integration:**
- [ ] Add ACB SQL adapter to dependencies
- [ ] Create SQLAlchemy models for metrics tables
- [ ] Create SQLAlchemy models for vector store
- [ ] Update MetricsCollector to use SqlAdapter
- [ ] Update VectorStore to use SqlAdapter
- [ ] Migrate existing database data (if needed)
- [ ] Update tests to mock SqlAdapter
- [ ] Remove manual threading.Lock code
- [ ] Remove raw sqlite3 imports

**Validation:**
- [ ] Metrics collection working correctly
- [ ] Vector store operations functional
- [ ] Async operations performing well
- [ ] Thread safety verified
- [ ] Migration script tested
- [ ] Backward compatibility maintained

### Phase 3: Cache & Embeddings

**Cache Migration:**
- [ ] Add ACB cache adapter to dependencies
- [ ] Update cache.py to use CacheAdapter
- [ ] Configure memory backend (development)
- [ ] Configure Redis backend (production - optional)
- [ ] Update tests to mock CacheAdapter
- [ ] Remove custom cache implementation

**Embedding Migration:**
- [ ] Add ACB embedding adapter to dependencies
- [ ] Update embeddings.py to use EmbeddingAdapter
- [ ] Configure OpenAI provider (current)
- [ ] Test SentenceTransformers provider (optional)
- [ ] Update vector_store.py integration
- [ ] Performance benchmark embedding generation

**Validation:**
- [ ] Cache hit/miss rates maintained
- [ ] Embedding generation performance acceptable
- [ ] Multiple provider support verified
- [ ] Integration with vector store working

### Phase 4: LSP Service

**Service Creation:**
- [ ] Create services/lsp/ directory structure
- [ ] Extract LSP infrastructure to LSPService
- [ ] Add MODULE_ID and MODULE_STATUS
- [ ] Add depends.set() registration
- [ ] Create tool-specific clients (Zuban, Skylos)
- [ ] Update LSPAdapter to use LSPService
- [ ] Update tool_proxy.py
- [ ] Write comprehensive test suite

**Validation:**
- [ ] LSP service discoverable via depends.get()
- [ ] Server lifecycle management working
- [ ] Health checks functioning
- [ ] Client connections stable
- [ ] Integration with LSPAdapter complete

### Phase 5: Pre-commit Infrastructure Removal

**Individual Adapter Settings:**
- [ ] Create settings/ directory structure
- [ ] Generate 10 individual adapter YAML files
- [ ] Create settings/loader.py with validation
- [ ] Create settings/groups.yml for custom groups
- [ ] Update QACheckConfig model to load from individual files
- [ ] Add CLI flags: --adapter, --adapters, --group
- [ ] Test loading individual adapter configs
- [ ] Test group execution (--fast, --comp)
- [ ] Verify async execution with caching

**Pre-commit Removal:**
- [ ] Remove .pre-commit-config.yaml entirely
- [ ] Remove dynamic_config.py (1000+ lines)
- [ ] Remove ConfigurationService.update_precommit_config()
- [ ] Remove all config generation logic
- [ ] Remove pre-commit dependency from pyproject.toml

**Custom Git Hooks:**
- [ ] Implement --install-hooks command
- [ ] Generate .git/hooks/pre-commit script
- [ ] Generate .git/hooks/pre-push script
- [ ] Test custom git hooks trigger correctly
- [ ] Verify --hook-mode flag behavior
- [ ] Create --uninstall-hooks command

**Validation:**
- [ ] Individual adapters executable via CLI
- [ ] Group execution working (--fast, --comp, --all)
- [ ] Custom git hooks triggering correctly
- [ ] No pre-commit dependency required
- [ ] All adapter settings loading correctly
- [ ] Cache working with content-based hashing
- [ ] Async execution performing well
- [ ] Migration guide complete

### Phase 6: Testing & Documentation

**Comprehensive Testing:**
- [ ] Integration tests for all ACB adapters
- [ ] End-to-end workflow testing
- [ ] Performance benchmarking (before/after)
- [ ] Load testing for database operations
- [ ] Concurrent execution testing
- [ ] Error handling and recovery testing

**Documentation Updates:**
- [ ] Update CLAUDE.md with ACB patterns
- [ ] Create ACB integration guide
- [ ] Update README.md
- [ ] Create migration guide
- [ ] Update API documentation
- [ ] Add ACB adapter examples

**Quality Assurance:**
- [ ] Code coverage ≥25% (target)
- [ ] All tests passing
- [ ] No performance regressions
- [ ] Memory usage acceptable
- [ ] Documentation complete
- [ ] Migration guide validated

### Post-Migration

**Monitoring:**
- [ ] Deploy to development environment
- [ ] Monitor for 1 week
- [ ] Collect performance metrics
- [ ] Address any issues
- [ ] Deploy to production

**Optional Enhancements:**
- [ ] Evaluate logger adapter migration
- [ ] Consider vector database upgrade
- [ ] Add monitoring adapter
- [ ] Implement storage adapter (S3 backup)

---

## 10. Agent Orchestration & Parallel Execution Strategy

### Overview

This section maps specialized AI agents to specific implementation phases, identifies parallel execution opportunities, and defines coordination patterns for accelerated delivery.

**83 Available Specialized Agents:**
- Programming Languages (8): Python, JavaScript, TypeScript, Go, Rust, Java, C/C++, Flutter
- Databases & Storage (9): PostgreSQL, MySQL, SQLite, Redis, Vector Databases
- Testing & Quality (5): General testing, pytest/hypothesis, test creation, consolidation
- Architecture & Design (6): Backend, authentication, microservices, performance
- Security & Compliance (3): Security auditing, authentication, critical reviews
- Meta & Optimization (13): Agent creation, code review, debugging, refactoring

---

### Agent-to-Phase Mapping

#### Phase 1: Core ACB Infrastructure Setup (Week 1)

**Lead Agents:**
- `architecture-council` (Opus) - System architecture decisions, dependency injection patterns
- `python-pro` (Sonnet) - Core Python implementation, ACB integration

**Supporting Agents:**
- `refactoring-specialist` (Sonnet) - Code restructuring for ACB patterns
- `acb-specialist` (Sonnet) - ACB framework expertise, adapter patterns

**Tasks:**
1. Add ACB to dependencies (`python-pro`)
2. Create ACB module registry (`architecture-council`)
3. Set up depends.get() patterns (`acb-specialist`)
4. Refactor existing code for DI (`refactoring-specialist`)

**Deliverables:**
- ACB installed and configured
- Module-level MODULE_ID constants
- Basic DI container setup

**Estimated Duration:** 5 days
**Parallelization:** None (foundation work, sequential)

---

#### Phase 2: QA Adapter Category Structure (Week 1-2)

**Lead Agents:**
- `python-pro` (Sonnet) - Adapter implementation
- `test-specialist` (Sonnet) - Test adapter patterns

**Supporting Agents:**
- `refactoring-specialist` (Sonnet) - Complexity reduction
- `documentation-specialist` (Sonnet) - Adapter documentation

**Tasks by Adapter:**

**2.1 Format Adapters** (`python-pro` + `test-specialist`)
- crackerjack/adapters/format/ruff.py
- crackerjack/adapters/format/mdformat.py

**2.2 Lint Adapters** (`python-pro` + `test-specialist`)
- crackerjack/adapters/lint/codespell.py

**2.3 Security Adapters** (`security-auditor` + `python-pro`)
- crackerjack/adapters/security/bandit.py
- crackerjack/adapters/security/gitleaks.py

**2.4 Type Adapters** (`python-pro` + `test-specialist`)
- crackerjack/adapters/type/zuban.py (QA version)

**2.5 Refactor Adapters** (`refactoring-specialist` + `python-pro`)
- crackerjack/adapters/refactor/refurb.py
- crackerjack/adapters/refactor/creosote.py

**2.6 Complexity Adapters** (`performance-engineer` + `python-pro`)
- crackerjack/adapters/complexity/complexipy.py

**2.7 Utility Adapters** (`python-pro` + `test-specialist`)
- crackerjack/adapters/utility/checks.py

**Parallelization Opportunity:**
```
Parallel Group 2A (Day 1-3):
├─ Format adapters (python-pro #1)
├─ Lint adapters (python-pro #2)
└─ Utility adapters (python-pro #3)

Parallel Group 2B (Day 4-6):
├─ Security adapters (security-auditor + python-pro #1)
├─ Type adapters (python-pro #2)
└─ Refactor adapters (refactoring-specialist + python-pro #3)

Parallel Group 2C (Day 7-8):
└─ Complexity adapters (performance-engineer + python-pro)
```

**Review Gate:** `code-reviewer` (Opus) - Protocol compliance, ACB patterns

**Estimated Duration:** 8 days (with 3 parallel streams)
**Sequential Duration:** 16 days (without parallelization)
**Time Saved:** 8 days (50% reduction)

---

#### Phase 3: Hook Orchestration & Execution (Week 2-3)

**Lead Agents:**
- `architecture-council` (Opus) - Orchestration design
- `python-pro` (Sonnet) - Core implementation

**Supporting Agents:**
- `performance-engineer` (Sonnet) - Async optimization
- `test-specialist` (Sonnet) - Test orchestration patterns

**Tasks:**

**3.1 Hook Orchestrator** (`architecture-council` + `python-pro`)
- Design async execution pipeline
- Implement dependency resolution
- Create group execution logic (--fast, --comp)

**3.2 Execution Strategies** (`performance-engineer` + `python-pro`)
- Parallel execution with asyncio
- Resource management
- Timeout handling

**3.3 Cache Integration** (`redis-specialist` + `python-pro`)
- Content-based caching
- Cache invalidation strategies
- Performance optimization

**Parallelization Opportunity:**
```
Sequential Foundation (Day 1-2):
└─ Hook Orchestrator design (architecture-council)

Parallel Group 3A (Day 3-7):
├─ Execution strategies (performance-engineer + python-pro #1)
└─ Cache integration (redis-specialist + python-pro #2)

Parallel Group 3B (Day 8-10):
├─ Test orchestration (test-specialist)
└─ Performance benchmarking (performance-engineer)
```

**Review Gate:** `architecture-council` (Opus) - Design patterns, scalability

**Estimated Duration:** 10 days (with 2 parallel streams)
**Sequential Duration:** 15 days
**Time Saved:** 5 days (33% reduction)

---

#### Phase 4: Configuration Management (Week 3-4)

**Lead Agents:**
- `python-pro` (Sonnet) - Configuration implementation
- `security-auditor` (Opus) - Security review

**Supporting Agents:**
- `documentation-specialist` (Sonnet) - Configuration documentation

**Tasks:**

**4.1 Individual Adapter Settings** (`python-pro`)
- Create settings/ruff.yml
- Create settings/bandit.yml
- Create settings/gitleaks.yml
- [... all other adapters]

**4.2 Settings Loader** (`python-pro`)
- YAML parsing and validation
- Settings inheritance (base → adapter)
- Environment variable overrides

**4.3 Security Hardening** (`security-auditor`)
- Input validation
- Path traversal prevention
- Secrets management

**Parallelization Opportunity:**
```
Parallel Group 4A (Day 1-3):
├─ Format adapter settings (python-pro #1)
├─ Lint adapter settings (python-pro #2)
├─ Security adapter settings (python-pro #3)
└─ Type adapter settings (python-pro #4)

Parallel Group 4B (Day 4-6):
├─ Refactor adapter settings (python-pro #1)
├─ Complexity adapter settings (python-pro #2)
├─ Utility adapter settings (python-pro #3)
└─ Settings loader implementation (python-pro #4)

Sequential Review (Day 7):
└─ Security audit (security-auditor)
```

**Review Gate:** `security-auditor` (Opus) - Security vulnerabilities, best practices

**Estimated Duration:** 7 days (with 4 parallel streams)
**Sequential Duration:** 14 days
**Time Saved:** 7 days (50% reduction)

---

#### Phase 5: LSP Integration (Week 4-5) - PARALLEL WITH PHASE 6

**Lead Agents:**
- `websocket-specialist` (Sonnet) - LSP protocol expertise
- `python-pro` (Sonnet) - Integration implementation

**Supporting Agents:**
- `architecture-council` (Opus) - LSP service design
- `test-specialist` (Sonnet) - LSP testing patterns

**Tasks:**

**5.1 Unified LSP Adapter** (`websocket-specialist` + `python-pro`)
- Consolidate zuban_adapter.py + skylos_adapter.py
- Implement LSP communication protocol
- Handle JSON-RPC messages

**5.2 LSP Service Layer** (`architecture-council` + `python-pro`)
- Design LSP service interface
- Implement connection pooling
- Handle workspace updates

**5.3 LSP Integration Tests** (`test-specialist`)
- Mock LSP servers
- Test error handling
- Performance benchmarks

**Parallelization Opportunity:**
```
Sequential Foundation (Day 1-2):
└─ LSP service design (architecture-council)

Parallel Group 5A (Day 3-7):
├─ Unified LSP adapter (websocket-specialist + python-pro #1)
├─ LSP service layer (python-pro #2)
└─ Integration tests (test-specialist)

Sequential Review (Day 8-10):
└─ WebSocket security review (security-auditor)
```

**Review Gate:** `websocket-specialist` (Sonnet) - Protocol compliance, error handling

**Estimated Duration:** 10 days (with 3 parallel streams)
**Sequential Duration:** 15 days
**Time Saved:** 5 days (33% reduction)

---

#### Phase 6: Async Test Execution (Week 4-5) - PARALLEL WITH PHASE 5

**Lead Agents:**
- `test-specialist` (Sonnet) - Test infrastructure
- `pytest-hypothesis-specialist` (Sonnet) - Advanced pytest patterns

**Supporting Agents:**
- `performance-engineer` (Sonnet) - Worker optimization
- `python-pro` (Sonnet) - Core implementation

**Tasks:**

**6.1 Intelligent Worker Detection** (`performance-engineer` + `python-pro`)
- Implement get_optimal_workers() algorithm
- CPU-based worker allocation
- Resource monitoring

**6.2 Test Markers & Isolation** (`pytest-hypothesis-specialist`)
- Add @pytest.mark.parallel_safe markers
- Add @pytest.mark.sequential markers
- Audit existing tests for parallel safety

**6.3 TestOrchestrator** (`test-specialist` + `python-pro`)
- ACB-integrated test orchestration
- Async execute_tests() method
- Cache integration for test results

**6.4 Configuration** (`python-pro`)
- Create settings/pytest.yml
- Update pyproject.toml with -n auto
- Worker strategy configuration

**Parallelization Opportunity:**
```
Parallel Group 6A (Day 1-5):
├─ Worker detection (performance-engineer + python-pro #1)
├─ Test markers audit (pytest-hypothesis-specialist)
├─ TestOrchestrator (test-specialist + python-pro #2)
└─ Configuration (python-pro #3)

Sequential Integration (Day 6-8):
└─ Integration testing & benchmarking (test-specialist)

Sequential Review (Day 9-10):
└─ Performance validation (performance-engineer)
```

**Review Gate:** `pytest-hypothesis-specialist` (Sonnet) - Test patterns, parallel safety

**Estimated Duration:** 10 days (with 4 parallel streams, concurrent with Phase 5)
**Sequential Duration:** 15 days
**Time Saved:** 5 days (33% reduction)

**CRITICAL:** Phases 5 and 6 can run **completely in parallel** - No dependencies between LSP integration and test execution improvements.

---

#### Phase 7: Database & Cache Migration (Week 5-6) - PARALLEL WITH PHASES 5-6

**Lead Agents:**
- `sqlite-specialist` (Sonnet) - SQLite optimization
- `redis-specialist` (Sonnet) - Cache implementation
- `vector-database-specialist` (Sonnet) - Vector operations

**Supporting Agents:**
- `python-pro` (Sonnet) - Integration code
- `database-operations-specialist` (Sonnet) - Database ops

**Tasks:**

**7.1 SQLite Migration** (`sqlite-specialist` + `python-pro`)
- Migrate metrics.py to ACB SQL adapter
- Database schema using ACB patterns
- Query optimization

**7.2 Vector Store Migration** (`vector-database-specialist` + `python-pro`)
- Migrate vector_store.py to ACB Vector adapter
- Embedding operations
- Similarity search optimization

**7.3 Cache Adapter** (`redis-specialist` + `python-pro`)
- Replace custom cache with ACB Cache adapter
- Content-based caching strategies
- Cache invalidation logic

**Parallelization Opportunity:**
```
Parallel Group 7A (Day 1-5):
├─ SQLite migration (sqlite-specialist + python-pro #1)
├─ Vector store migration (vector-database-specialist + python-pro #2)
└─ Cache adapter (redis-specialist + python-pro #3)

Sequential Integration (Day 6-8):
└─ Integration testing (database-operations-specialist)

Sequential Review (Day 9-10):
└─ Performance benchmarking (performance-engineer)
```

**Review Gate:** `database-operations-specialist` (Sonnet) - Schema design, query optimization

**Estimated Duration:** 10 days (with 3 parallel streams, concurrent with Phases 5-6)
**Sequential Duration:** 15 days
**Time Saved:** 5 days (33% reduction)

---

#### Phase 8: Pre-commit Infrastructure Removal (Week 6-7)

**Lead Agents:**
- `python-pro` (Sonnet) - Custom git hooks implementation
- `architecture-council` (Opus) - Hook architecture design

**Supporting Agents:**
- `security-auditor` (Opus) - Git hook security
- `test-specialist` (Sonnet) - Hook testing

**Tasks:**

**8.1 Custom Git Hooks** (`python-pro`)
- Generate .git/hooks/pre-commit script
- Generate .git/hooks/pre-push script
- Hook installation logic

**8.2 Dynamic Config Removal** (`refactoring-specialist` + `python-pro`)
- Delete dynamic_config.py (1000+ lines)
- Remove pre-commit-config.yaml generation
- Clean up unused imports

**8.3 Adapter Group Execution** (`architecture-council` + `python-pro`)
- Implement --adapter flag
- Implement --adapters flag
- Implement --fast and --comp groups

**8.4 Migration Testing** (`test-specialist`)
- Test all execution modes
- Verify hook triggers
- Performance regression testing

**Parallelization Opportunity:**
```
Sequential Foundation (Day 1-2):
└─ Hook architecture design (architecture-council)

Parallel Group 8A (Day 3-7):
├─ Custom git hooks (python-pro #1)
├─ Dynamic config removal (refactoring-specialist + python-pro #2)
└─ Group execution (python-pro #3)

Sequential Integration (Day 8-10):
├─ Migration testing (test-specialist)
└─ Security audit (security-auditor)
```

**Review Gate:** `security-auditor` (Opus) - Git hook security, privilege escalation risks

**Estimated Duration:** 10 days (with 3 parallel streams)
**Sequential Duration:** 15 days
**Time Saved:** 5 days (33% reduction)

---

#### Phase 9: MCP Server Enhancement (Week 7)

**Lead Agents:**
- `websocket-specialist` (Sonnet) - Real-time communication
- `python-pro` (Sonnet) - Server implementation

**Supporting Agents:**
- `architecture-council` (Opus) - Server architecture
- `security-auditor` (Opus) - MCP security review

**Tasks:**

**9.1 ACB Integration** (`websocket-specialist` + `python-pro`)
- Integrate MCP server with ACB DI
- Use ACB adapters (SQL, Cache, Logger)
- Async execution patterns

**9.2 Real-time Progress** (`websocket-specialist`)
- WebSocket progress streaming
- Job status updates
- Error notifications

**9.3 Security Hardening** (`security-auditor`)
- Authentication/authorization
- Input validation
- Rate limiting

**Parallelization Opportunity:**
```
Sequential Foundation (Day 1):
└─ Server architecture review (architecture-council)

Parallel Group 9A (Day 2-4):
├─ ACB integration (websocket-specialist + python-pro #1)
└─ Real-time progress (websocket-specialist + python-pro #2)

Sequential Review (Day 5):
└─ Security audit (security-auditor)
```

**Review Gate:** `security-auditor` (Opus) - MCP security vulnerabilities

**Estimated Duration:** 5 days (with 2 parallel streams)
**Sequential Duration:** 7 days
**Time Saved:** 2 days (29% reduction)

---

#### Phase 10: Final Integration & Testing (Week 7-8)

**Lead Agents:**
- `test-specialist` (Sonnet) - Integration testing
- `performance-engineer` (Sonnet) - Performance validation

**Supporting Agents:**
- `code-reviewer` (Opus) - Final code review
- `critical-audit-specialist` (Opus) - Comprehensive audit
- `documentation-specialist` (Sonnet) - Documentation finalization

**Tasks:**

**10.1 End-to-End Testing** (`test-specialist`)
- Full workflow testing
- Regression testing
- Edge case validation

**10.2 Performance Benchmarking** (`performance-engineer`)
- Measure execution times
- Memory profiling
- Cache effectiveness

**10.3 Code Quality Review** (`code-reviewer` + `critical-audit-specialist`)
- Architecture review
- Code quality audit
- Security final check

**10.4 Documentation** (`documentation-specialist`)
- Update README.md
- Create migration guide
- API documentation

**Parallelization Opportunity:**
```
Parallel Group 10A (Day 1-5):
├─ End-to-end testing (test-specialist)
├─ Performance benchmarking (performance-engineer)
└─ Documentation (documentation-specialist)

Sequential Review (Day 6-7):
├─ Code review (code-reviewer)
└─ Critical audit (critical-audit-specialist)
```

**Final Gate:** `critical-audit-specialist` (Opus) - Production readiness review

**Estimated Duration:** 7 days (with 3 parallel streams)
**Sequential Duration:** 10 days
**Time Saved:** 3 days (30% reduction)

---

### Parallel Execution Timeline

**Traditional Sequential Approach:** 127 days (25.4 weeks)

**Optimized Parallel Approach:** 72 days (14.4 weeks)

**Time Saved:** 55 days (43% reduction)

```
Week 1: Phase 1 (Core ACB) [Sequential - Foundation]
        └─ architecture-council + python-pro

Week 1-2: Phase 2 (QA Adapters) [3 Parallel Streams]
          ├─ Stream A: Format/Lint/Utility (python-pro #1-3)
          ├─ Stream B: Security/Type/Refactor (various #1-3)
          └─ Stream C: Complexity (performance-engineer)

Week 2-3: Phase 3 (Hook Orchestration) [2 Parallel Streams]
          ├─ Stream A: Execution strategies (performance-engineer + python-pro)
          └─ Stream B: Cache integration (redis-specialist + python-pro)

Week 3-4: Phase 4 (Configuration) [4 Parallel Streams]
          ├─ Stream A: Format/Lint settings (python-pro #1-2)
          ├─ Stream B: Security/Type settings (python-pro #3-4)
          ├─ Stream C: Refactor/Complexity settings (python-pro #5-6)
          └─ Stream D: Settings loader (python-pro #7)

Week 4-5: TRIPLE PARALLEL EXECUTION [11 Parallel Streams]
          │
          ├─ Phase 5 (LSP Integration) [3 Streams]
          │  ├─ LSP adapter (websocket-specialist + python-pro #1)
          │  ├─ LSP service (python-pro #2)
          │  └─ Tests (test-specialist)
          │
          ├─ Phase 6 (Async Tests) [4 Streams]
          │  ├─ Worker detection (performance-engineer + python-pro #3)
          │  ├─ Test markers (pytest-hypothesis-specialist)
          │  ├─ TestOrchestrator (test-specialist + python-pro #4)
          │  └─ Configuration (python-pro #5)
          │
          └─ Phase 7 (Database/Cache) [4 Streams]
             ├─ SQLite (sqlite-specialist + python-pro #6)
             ├─ Vector store (vector-database-specialist + python-pro #7)
             ├─ Cache (redis-specialist + python-pro #8)
             └─ Integration tests (database-operations-specialist)

Week 6-7: Phase 8 (Pre-commit Removal) [3 Parallel Streams]
          ├─ Stream A: Custom hooks (python-pro #1)
          ├─ Stream B: Dynamic config removal (refactoring-specialist)
          └─ Stream C: Group execution (python-pro #2)

Week 7: Phase 9 (MCP Enhancement) [2 Parallel Streams]
        ├─ Stream A: ACB integration (websocket-specialist + python-pro)
        └─ Stream B: Real-time progress (websocket-specialist)

Week 7-8: Phase 10 (Final Testing) [3 Parallel Streams]
          ├─ Stream A: E2E testing (test-specialist)
          ├─ Stream B: Performance (performance-engineer)
          └─ Stream C: Documentation (documentation-specialist)

Final Review: code-reviewer + critical-audit-specialist
```

---

### Agent Coordination Patterns

#### 1. Task Handoff Protocol

**Pattern:** Lead agent completes core work → Supporting agents enhance/review

**Example (Phase 2 - Bandit Adapter):**
```
Step 1: python-pro implements basic BanditAdapter
        └─ Deliverable: Working adapter with core functionality

Step 2: security-auditor reviews implementation
        └─ Deliverable: Security recommendations

Step 3: python-pro applies security fixes
        └─ Deliverable: Hardened adapter

Step 4: test-specialist adds test coverage
        └─ Deliverable: Tested adapter

Step 5: documentation-specialist documents API
        └─ Deliverable: Complete adapter with docs
```

#### 2. Parallel Work with Shared Context

**Pattern:** Multiple agents work on independent components, share integration points

**Example (Week 4-5 Triple Parallel):**
```
Shared Context:
- ACB DI container patterns
- Settings/config structure
- Common test fixtures

Independent Work:
- Phase 5: LSP adapters (websocket-specialist)
- Phase 6: Test orchestration (test-specialist)
- Phase 7: Database migration (sqlite-specialist)

Integration Points:
- All use depends.get() for DI
- All use settings/*.yml pattern
- All use common test utilities
```

#### 3. Review Gate Pattern

**Pattern:** Opus-level agents provide architecture/security review gates

**Example (Phase 3 - Hook Orchestration):**
```
Implementation: python-pro + performance-engineer
                └─ Build async execution pipeline

Review Gate: architecture-council (Opus)
             └─ Validate:
                - Scalability
                - Resource management
                - Error handling
                - ACB pattern compliance

Approval: Code merged, next phase starts
Rejection: Refactor required, re-review
```

#### 4. Conflict Resolution Strategy

**When multiple agents produce conflicting solutions:**

**Resolution Process:**
1. **Identify conflict** - Automated detection during integration
2. **Escalate to architecture-council** (Opus) - Design decision authority
3. **Analyze trade-offs** - Performance vs. maintainability vs. security
4. **Make decision** - Document rationale
5. **Update affected code** - Implementing agent makes changes
6. **Re-review** - Ensure consistency

**Example Conflict:**
```
Conflict: test-specialist suggests process-level isolation
          vs.
          performance-engineer suggests shared memory for speed

Resolution by architecture-council:
- Default: Process-level (safety first)
- Option: Shared memory mode with --fast-unsafe flag
- Rationale: Safety > speed, but power users get option
- Documentation: Clear warnings about --fast-unsafe risks
```

#### 5. Progress Synchronization

**Daily Synchronization Points:**
- Each agent reports completed tasks to shared context
- Blocking issues flagged immediately
- architecture-council adjusts timeline if needed

**Weekly Milestones:**
- Week 1: Core ACB + QA adapters complete
- Week 2-3: Hook orchestration + configuration complete
- Week 4-5: LSP + async tests + database (triple parallel)
- Week 6-7: Pre-commit removal + MCP enhancement
- Week 7-8: Final testing + review

---

### Resource Allocation

**Agent Concurrency Limits:**
- Max 11 parallel streams (Week 4-5 peak)
- Opus agents (architecture-council, security-auditor, code-reviewer): 1 concurrent task each
- Sonnet agents (python-pro, test-specialist, etc.): Multiple instances possible
- Haiku agents: Fast tasks, unlimited concurrency

**Suggested python-pro Instances:**
- Week 1: 2 instances (Core ACB + adapters)
- Week 2-4: 4-8 instances (Peak parallelization)
- Week 5-7: 3-5 instances (Integration phase)
- Week 8: 2 instances (Final polish)

**Review Capacity:**
- code-reviewer (Opus): 1 review per day
- architecture-council (Opus): 2 design reviews per week
- critical-audit-specialist (Opus): Final review only (Week 8)

---

### Risk Mitigation

**Risk 1: Agent Coordination Failures**
- **Mitigation:** Daily sync meetings, shared context document
- **Fallback:** architecture-council arbitrates conflicts

**Risk 2: Parallel Work Integration Issues**
- **Mitigation:** Define clear interfaces early, integration testing
- **Fallback:** Sequential integration if parallel fails

**Risk 3: Agent Availability**
- **Mitigation:** Assign backup agents for critical paths
- **Fallback:** Extend timeline if agent unavailable

**Risk 4: Scope Creep**
- **Mitigation:** architecture-council enforces scope boundaries
- **Fallback:** Defer enhancements to post-migration phase

---

### Success Metrics

**Velocity Metrics:**
- **Target:** 72 days (14.4 weeks) with parallelization
- **Baseline:** 127 days (25.4 weeks) sequential
- **Improvement:** 43% faster delivery

**Quality Metrics:**
- Code review pass rate: ≥90%
- Test coverage: ≥25% (target)
- Security audit: 0 critical vulnerabilities
- Performance: No regressions

**Agent Utilization:**
- Opus agents: 80% utilization (design/review)
- Sonnet agents: 90% utilization (implementation)
- Haiku agents: 50% utilization (fast tasks)

---

## Summary of Benefits

### Code Reduction

| Component | Before | After | Savings |
|-----------|--------|-------|---------|
| **LSP Adapters** | 477 lines | 250 lines | -47% |
| **Database Code** | 800 lines | 50 lines | -94% |
| **Cache Code** | 400 lines | 20 lines | -95% |
| **Embeddings** | 300 lines | 30 lines | -90% |
| **Dynamic Config** | 1000 lines | 0 lines | -100% |
| **Pre-commit Config** | 103 lines | 0 lines | -100% |
| **Config Generation** | 400 lines | 0 lines | -100% |
| **Total** | ~3,480 lines | ~350 lines | -90% |

### Quality Improvements

1. **Maintainability** - ACB handles infrastructure concerns
2. **Testability** - Easy mocking and isolation via DI
3. **Extensibility** - Add new tools/features easily
4. **Performance** - Async, pooling, caching built-in
5. **Reliability** - Battle-tested ACB adapters
6. **Type Safety** - Protocol-based contracts
7. **Documentation** - ACB provides comprehensive docs
8. **Configuration Simplicity** - Individual YAML files per adapter
9. **Execution Flexibility** - Run any adapter individually or in groups
10. **No External Dependencies** - Custom git hooks, no pre-commit framework

### Developer Experience

1. **Less Boilerplate** - No manual connection management
2. **Consistent Patterns** - All adapters follow same structure
3. **Auto-Discovery** - depends.get() anywhere
4. **Better IDE Support** - Type hints throughout
5. **Easier Testing** - Mock ACB adapters easily
6. **Modern Python** - Async/await, protocols, DI
7. **Fine-Grained Control** - Run specific adapters on demand
8. **Transparent Configuration** - One file per adapter, easy to understand
9. **Custom Groups** - Define your own adapter groups
10. **Full Hook Control** - No pre-commit limitations or complexity

---

## Questions for Review

1. **LSP Consolidation** - Approve unifying zuban_adapter.py + skylos_adapter.py?
2. **Database Migration** - Ready to migrate to ACB SQL adapter?
3. **Priority Order** - Agree with phased approach (LSP → SQL → Cache → Embeddings → Pre-commit)?
4. **Pre-commit Infrastructure** - Approve COMPLETE removal of .pre-commit-config.yaml?
5. **Individual Settings** - Approve one YAML file per adapter architecture?
6. **Custom Git Hooks** - Approve replacing pre-commit with custom git hooks?
7. **Dynamic Config** - Approve complete removal of dynamic_config.py (1000+ lines)?
8. **Execution Modes** - Approve individual + group execution architecture?
9. **Timeline** - 7-week plan acceptable or adjust priorities?
10. **Optional Features** - Which optional ACB adapters should we prioritize?
11. **Testing Strategy** - Sufficient test coverage requirements?
12. **Documentation** - Additional documentation needed?

---

## Next Steps

1. **Review this plan** - Team discussion and approval
2. **Set up ACB environment** - Add ACB to dependencies
3. **Start Phase 1** - LSP consolidation (Week 1)
4. **Weekly check-ins** - Review progress and adjust
5. **Continuous testing** - Ensure no regressions
6. **Documentation updates** - Keep docs in sync
7. **Deploy incrementally** - Validate each phase before next

---

**End of ACB Integration Plan**

**Last Updated:** 2025-10-09
**Document Owner:** Crackerjack Development Team
**Status:** ✅ Ready for Review
