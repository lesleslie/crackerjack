# ADR 0001: ACB-Based Quality Assurance Framework Architecture

**Date:** 2025-10-09
**Status:** ‚úÖ Accepted
**Decision Maker:** Architecture Council (Claude Code)
**Reviewers:** Project Architect, Lead Developer

## Context

Crackerjack currently uses pre-commit hooks for quality assurance checks. We need to migrate to an ACB (Anthropic Component Base) adapter-based architecture to:

1. **Improve maintainability** - Modular, testable adapter pattern
2. **Enable extensibility** - Easy to add new quality checks
3. **Support async operations** - Better performance with parallel execution
4. **Standardize patterns** - Follow FastBlocks ACB reference architecture
5. **Facilitate AI integration** - Structured results for AI agents

## Decision

We will implement a **three-layer ACB-based QA framework**:

### Layer 1: Adapters (Check Execution)
- **Location:** `crackerjack/adapters/qa/`
- **Responsibility:** Execute individual quality checks (lint, format, type-check, etc.)
- **Pattern:** Inherit from `QAAdapterBase`, implement `check()`, `validate_config()`, `get_default_config()`
- **Registration:** Automatic via `depends.set(self)` in `__init__`

### Layer 2: Services (Orchestration)
- **Location:** `crackerjack/services/qa_orchestrator.py`
- **Responsibility:** Coordinate multiple QA adapters, aggregate results
- **Pattern:** Service class that uses adapters (not an adapter itself)
- **Execution:** Support parallel and sequential check execution

### Layer 3: Models (Data)
- **Location:** `crackerjack/models/qa_*.py`
- **Responsibility:** Define data structures (`QAResult`, `QACheckConfig`, etc.)
- **Pattern:** Pydantic models with validation and helper methods

## Alternatives Considered

### Alternative 1: Keep Pre-commit Hooks
**Rejected because:**
- Hard to extend with new checks
- Limited to synchronous execution
- Difficult to integrate with AI agents
- No structured result format

### Alternative 2: Make Orchestrator an Adapter
**Rejected because:**
- Orchestrators don't have a single check type
- Orchestrators don't produce single results
- Violates single responsibility principle
- Creates awkward protocol violations

### Alternative 3: Separate `models_qa/` Directory
**Rejected because:**
- Crackerjack uses single `models/` directory
- Reduces discoverability
- Complicates imports
- Inconsistent with existing patterns

### Alternative 4: Synchronous-Only Execution
**Rejected because:**
- Blocks event loop during checks
- Prevents parallel execution
- Poor performance at scale
- Doesn't leverage async benefits

## Consequences

### Positive
- ‚úÖ **Modular architecture** - Each adapter is independent and testable
- ‚úÖ **ACB compliance** - Follows Anthropic's official patterns
- ‚úÖ **Extensibility** - New checks require ~50 lines of code
- ‚úÖ **Performance** - Parallel async execution
- ‚úÖ **AI integration** - Structured `QAResult` objects
- ‚úÖ **Type safety** - Full type annotations and runtime checks
- ‚úÖ **Maintainability** - Clear separation of concerns

### Negative
- ‚ö†Ô∏è **Learning curve** - Developers need to understand ACB patterns
- ‚ö†Ô∏è **Initial effort** - Migration requires ~7 hours of development
- ‚ö†Ô∏è **Dependencies** - Requires ACB package installation
- ‚ö†Ô∏è **Testing complexity** - Need both unit and integration tests

### Neutral
- üìù **Documentation** - Comprehensive docs created (16,000+ words)
- üìù **Migration path** - Clear 4-phase implementation plan
- üìù **Backward compatibility** - Can run parallel to pre-commit during transition

## Implementation

### Directory Structure
```
crackerjack/
‚îú‚îÄ‚îÄ adapters/
‚îÇ   ‚îî‚îÄ‚îÄ qa/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ base.py              # QAAdapterBase, QAAdapterProtocol
‚îÇ       ‚îú‚îÄ‚îÄ ruff_format.py       # Example: Ruff formatter
‚îÇ       ‚îú‚îÄ‚îÄ pyright.py           # Example: Type checking
‚îÇ       ‚îî‚îÄ‚îÄ bandit.py            # Example: Security scanning
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ qa_results.py            # QAResult, status enums, types
‚îÇ   ‚îî‚îÄ‚îÄ qa_config.py             # Config models
‚îî‚îÄ‚îÄ services/
    ‚îî‚îÄ‚îÄ qa_orchestrator.py       # Orchestration service
```

### Key Classes

**QAAdapterBase:**
```python
class QAAdapterBase(AdapterBase):
    MODULE_ID: UUID              # Static UUID7 for identification
    MODULE_STATUS: str           # "stable", "experimental", etc.

    async def check(...) -> QAResult
    async def validate_config(...) -> bool
    def get_default_config() -> QACheckConfig
```

**QAOrchestrator:**
```python
class QAOrchestrator:
    def register_adapter(adapter: QAAdapterProtocol)
    def unregister_adapter(adapter_id: UUID)
    async def run_checks(...) -> list[QAResult]
```

**QAResult:**
```python
@dataclass
class QAResult:
    check_id: UUID
    check_name: str
    check_type: QACheckType      # LINT, FORMAT, TYPE_CHECK, etc.
    status: QAResultStatus       # SUCCESS, FAILURE, WARNING, etc.
    message: str
    details: str
    files_checked: list[Path]
    issues_found: int
    execution_time_ms: float
```

## Validation

### ACB Pattern Compliance
- ‚úÖ Inherits from `acb.config.AdapterBase`
- ‚úÖ Static `MODULE_ID` (UUID7) and `MODULE_STATUS`
- ‚úÖ Settings extend `acb.config.Settings`
- ‚úÖ Dependency injection via `depends.set(self)`
- ‚úÖ Runtime-checkable protocol definition
- ‚úÖ Async operation support
- ‚úÖ Type safety with full annotations

### Integration with Existing Codebase
- ‚úÖ Follows `adapters/ai/` organizational pattern
- ‚úÖ Integrates with existing `services/` layer
- ‚úÖ Uses existing `models/` directory structure
- ‚úÖ Compatible with `WorkflowOrchestrator`
- ‚úÖ Supports existing DI container patterns

## Risks and Mitigation

| Risk | Mitigation |
|------|-----------|
| ACB dependency unavailable | Well-documented fallback patterns |
| Breaking existing workflows | Incremental adoption, parallel systems |
| Performance regression | Async patterns, caching built in |
| Test coverage gaps | Comprehensive test plan included |
| Developer confusion | 16,000+ words of documentation |

## Timeline

### Phase 1: Foundation (Required - 1 hour)
- Move models to `models/` directory
- Create `QAOrchestrator` service
- Update imports

### Phase 2: Enhancement (Recommended - 2 hours)
- Add `CleanupMixin` for resource management
- Add `AdapterMetadata` for discovery
- Create example adapters

### Phase 3: Integration (Recommended - 2 hours)
- Wire up in main workflow
- Add CLI flags
- Integrate with coordinators

### Phase 4: Testing (Required - 2 hours)
- Unit tests for base adapter
- Integration tests for orchestrator
- Example adapter tests

**Total Estimated Time:** 7 hours

## Success Metrics

**Technical Metrics:**
- Zero breaking changes to existing workflows
- Test coverage ‚â• 80% for new code
- All type checks pass (zuban/pyright)
- Performance within 10% of pre-commit baseline

**Quality Metrics:**
- At least 3 concrete adapters implemented
- Documentation reviewed by 2+ developers
- All linters pass (ruff, bandit, etc.)
- Coverage ratchet maintained

**Adoption Metrics:**
- Migration completed within 1 sprint
- Zero critical bugs in production
- Developer feedback score ‚â• 4/5
- Reduced time to add new checks by 50%

## References

- **Detailed Review:** `/docs/qa-framework-architecture-review.md`
- **Implementation Plan:** `/docs/qa-framework-implementation-plan.md`
- **Quick Reference:** `/docs/qa-framework-quick-reference.md`
- **Executive Summary:** `/docs/qa-framework-review-summary.md`
- **ACB Documentation:** https://acb.anthropic.com
- **FastBlocks Reference:** `crackerjack/adapters/ai/claude.py`

## Decision Log

**2025-10-09:** Initial architectural review completed
- Approved three-layer architecture (adapters/services/models)
- Rejected separate `models_qa/` directory
- Rejected orchestrator-as-adapter pattern
- Required consolidation of models into main `models/` directory
- Required creation of `QAOrchestrator` service

**Approval:** Architecture Council
**Next Review:** 2025-11-09 (30 days) or after Phase 4 completion

---

## Appendix A: Example Concrete Adapter

```python
# adapters/qa/ruff_format.py
from uuid import UUID
from crackerjack.adapters.qa.base import QAAdapterBase, QABaseSettings
from crackerjack.models.qa_results import QAResult, QAResultStatus, QACheckType

class RuffFormatSettings(QABaseSettings):
    line_length: int = 88
    check_mode: bool = False  # Auto-fix if False

class RuffFormatAdapter(QAAdapterBase):
    MODULE_ID = UUID("01937d86-5f2a-7b3c-9d1e-a2b3c4d5e6f0")
    MODULE_STATUS = "stable"

    def __init__(self):
        super().__init__()
        self.settings = RuffFormatSettings()

    async def check(self, files=None, config=None):
        # Run ruff format check/fix
        cmd = ["ruff", "format"]
        if self.settings.check_mode:
            cmd.append("--check")
        # Execute and return QAResult
        ...

    async def validate_config(self, config):
        # Check ruff is available
        ...

    def get_default_config(self):
        return QACheckConfig(
            enabled=True,
            timeout_seconds=60,
            file_patterns=["**/*.py"],
        )
```

## Appendix B: Integration Example

```python
# Example workflow integration
from crackerjack.services.qa_orchestrator import QAOrchestrator
from crackerjack.adapters.qa.ruff_format import RuffFormatAdapter
from crackerjack.adapters.qa.pyright import PyrightAdapter

# Create and configure orchestrator
orchestrator = QAOrchestrator(config)

# Register quality check adapters
orchestrator.register_adapter(RuffFormatAdapter())
orchestrator.register_adapter(PyrightAdapter())

# Run all checks in parallel
results = await orchestrator.run_checks(files=changed_files)

# Process results
for result in results:
    if result.is_failure:
        print(f"‚ùå {result.check_name}: {result.message}")
        # Trigger AI agent if needed
    else:
        print(f"‚úÖ {result.check_name}: {result.message}")
```

## Appendix C: Testing Strategy

**Unit Tests:**
- Test `QAAdapterBase` base functionality
- Test `QABaseSettings` validation
- Test file pattern matching (`_should_check_file`)
- Test each concrete adapter in isolation

**Integration Tests:**
- Test `QAOrchestrator` with multiple adapters
- Test parallel vs sequential execution
- Test error handling and recovery
- Test result aggregation

**End-to-End Tests:**
- Test full workflow with real files
- Test CLI integration
- Test AI agent integration
- Test performance benchmarks

---

**Signed:** Architecture Council (Claude Code)
**Date:** 2025-10-09
**Status:** ‚úÖ Accepted - Ready for Implementation
